{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Standard Operating Procedure for ALL-ALS Data Updates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Generate View Name to Class Name Mapping\n",
        "\n",
        "This first step is to analyze the raw CSV files from the v2 data release to extract the 'Form Name' from each file. This 'Form Name' will be used to map to the class name in the data model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'form_name' column not found in v_ALLALS_PR_PREVOGCVH.csv\n",
            "Mappings saved to /home/ramayyala/Documents/data-model/form_name_mappings.json\n",
            "ASSEAELOG: Adverse Event (AE) Log\n",
            "ASSEALSFRSR: ALSFRS-R\n",
            "ASSEALSFRSRSAQ: ALSFRS-R and Speech Anchor Questions\n",
            "ASSEALSHIST: ALS History\n",
            "ASSEBLDCOL: Blood Collection (ASSESS)\n",
            "ASSECONMD: Concomitant Medication Log\n",
            "ASSECSFCO: Cerebral Spinal Fluid (CSF) Collection\n",
            "ASSEDEMOG: Demographics\n",
            "ASSEDSA: Digital Speech Assessment\n",
            "ASSEDSAUI: Digital Speech Assessment User Information\n",
            "ASSEECASCGI: ECAS (Edinburgh Cognitive and Behavioral ALS Screen) - Caregiver Interview\n",
            "ASSEECAS: ECAS (Edinburgh Cognitive and Behavioral ALS Screen)\n",
            "ASSEELCONLMP: Lumbar Puncture Eligibility Confirmation\n",
            "ASSEELCONREG: Enrollment Confirmation\n",
            "ASSEELIGCRIREG2: Eligibility Criteria (ASSESS Control)\n",
            "ASSEELIGCRISYM2: Eligibility Criteria (ASSESS Symptomatic)\n",
            "ASSEELIGCRITLMP: Lumbar Puncture Eligibility Criteria\n",
            "ASSEELIGCRITREG: Eligibility Criteria (ASSESS Control)\n",
            "ASSEELIGCRITSYM: Eligibility Criteria (ASSESS Symptomatic)\n",
            "ASSEFAMHIST: Family History\n",
            "ASSEHHD: Modified Hand-Held Dynamometry (HHD)\n",
            "ASSEICFCSF: Informed Consent Log: CSF Collection\n",
            "ASSEICF: Informed Consent Log\n",
            "ASSEKEYDEV: Key Devices and Procedures Log\n",
            "ASSEMEDHX: Medical History\n",
            "ASSEPARTFINDI: ASSESS Participant Final Disposition\n",
            "ASSEPDEVAD: Protocol Deviation Log\n",
            "ASSEPRALSGENTST: Prior ALS Genetic Testing\n",
            "ASSEVC: Vital Capacity (VC)\n",
            "ASSEVISTYPE: Visit Type\n",
            "ASSEVITSIGN: Vital Signs (ASSESS)\n",
            "NPROREGASSESS: Enrollment in NeuroPRO\n",
            "NPROREG: Enrollment in NeuroPRO\n",
            "PREVAELOG: Adverse Event (AE) Log\n",
            "PREVBLDCOLINC: Blood Collection (PREVENT In-Clinic)\n",
            "PREVBLDCOLREM: Blood Collection (PREVENT Remote)\n",
            "PREVCONMD: Concomitant Medication Log\n",
            "PREVCSFCO: Cerebral Spinal Fluid (CSF) Collection\n",
            "PREVDEMOG: Demographics\n",
            "PREVDSA: Digital Speech Assessment\n",
            "PREVDSAUI: Digital Speech Assessment User Information\n",
            "PREVECASCGI: ECAS (Edinburgh Cognitive and Behavioral ALS Screen) - Caregiver Interview\n",
            "PREVECAS: ECAS (Edinburgh Cognitive and Behavioral ALS Screen)\n",
            "PREVELCONGEN: Enrollment Confirmation (PREVENT Genetic Testing Sub-Study)\n",
            "PREVELCONLMP: Lumbar Puncture Eligibility Confirmation\n",
            "PREVELCONREG: Enrollment Confirmation\n",
            "PREVELIGCRITA2: Eligibility Criteria (PREVENT)\n",
            "PREVELIGCRITGEN: Eligibility Criteria (PREVENT Genetic Testing Sub-Study)\n",
            "PREVELIGCRITLMP: Lumbar Puncture Eligibility Criteria\n",
            "PREVELIGCRITREG: Eligibility Criteria (PREVENT)\n",
            "PREVELIGCRTGEN2: Eligibility Criteria (PREVENT Genetic Testing Sub-Study)\n",
            "PREVEMG: EMG\n",
            "PREVENDVISFRM: PREVENT End of Visit Form\n",
            "PREVFAMHIST: Family History\n",
            "PREVFUTELEV: Follow-Up Telephone Visit\n",
            "PREVGENCOUNREF: Genetic Counseling Referral\n",
            "PREVGENCRPL: ALS Gene Carrier Research Participation Log\n",
            "PREVGENTSTRES: PREVENT Genetic Testing Results\n",
            "PREVGST: Grip Strength Testing\n",
            "PREVHHD: Handheld Dynamometry (HHD)\n",
            "PREVICF: Informed Consent Log\n",
            "PREVICFGEN: Informed Consent Log: Genetic Testing Sub-Study\n",
            "PREVKEYDEV: Key Devices and Procedures Log\n",
            "PREVMEDHX: Medical History\n",
            "PREVMIRPARTI: MIR (Participant)\n",
            "PREVMIRSCRPR: MIR Screener (Participant)\n",
            "PREVMIRSCRSP: MIR Screener (Study Partner)\n",
            "PREVMIRSTYP: MIR (Study Partner)\n",
            "PREVNUROEX: Neurological Examination\n",
            "PREVPARTFINDIS: PREVENT Participant Final Disposition\n",
            "PREVPDEVAD: Protocol Deviation Log\n",
            "PREVPHENOCONVER: Phenoconversion\n",
            "PREVPHEXM: Physical Examination\n",
            "PREVPRALSGENTST: Prior ALS Genetic Testing\n",
            "PREVPREGENCONAP: Pre-Test Genetic Counseling Appointment\n",
            "PREVPSTGENCONAP: Return of Genetic Results Counseling Appointment\n",
            "PREVSYMPQUES: PREVENT Symptom Questionnaire\n",
            "PREVVC: Vital Capacity (VC)\n",
            "PREVVISTYPE: Visit Type\n",
            "PREVVITSIGN: Vital Signs (PREVENT)\n",
            "PREVWEIGHT: Weight\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "import json\n",
        "\n",
        "def get_form_names_from_datasets(base_dir):\n",
        "    datasets = [\"ASSESS\", \"PREVENT\"]\n",
        "    form_name_mapping = {}\n",
        "\n",
        "    for dataset in datasets:\n",
        "        dataset_files_path = os.path.join(base_dir, dataset, 'files')\n",
        "        if not os.path.isdir(dataset_files_path):\n",
        "            print(f\"Directory not found: {dataset_files_path}\")\n",
        "            continue\n",
        "\n",
        "        for filename in os.listdir(dataset_files_path):\n",
        "            if filename.endswith(\".csv\"):\n",
        "                file_path = os.path.join(dataset_files_path, filename)\n",
        "                try:\n",
        "                    with open(file_path, 'r', encoding='utf-8') as csvfile:\n",
        "                        reader = csv.reader(csvfile)\n",
        "                        header = next(reader)\n",
        "                        if \"form_name\" in header:\n",
        "                            form_name_index = header.index(\"form_name\")\n",
        "                            try:\n",
        "                                first_row = next(reader)\n",
        "                                form_name = first_row[form_name_index]\n",
        "                                # Clean up the filename to use as a key\n",
        "                                clean_filename = os.path.splitext(filename)[0].replace('v_ALLALS_AS_', '').replace('v_ALLALS_PV_', '').replace('v_ALLALS_PR_', '').replace('-', '_')\n",
        "                                form_name_mapping[clean_filename] = form_name\n",
        "                            except StopIteration:\n",
        "                                print(f\"File is empty (after header): {filename}\")\n",
        "                        else:\n",
        "                            print(f\"'form_name' column not found in {filename}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing file {filename}: {e}\")\n",
        "\n",
        "    return form_name_mapping\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # The base directory where the ASSESS and PREVENT folders are located.\n",
        "    base_directory = \"/home/ramayyala/Documents/data-model/data/ALL_ALS/v3-DEC\"\n",
        "    mappings = get_form_names_from_datasets(base_directory)\n",
        "\n",
        "    # Save the mappings to a file in the root of the project\n",
        "    output_file_path = \"/home/ramayyala/Documents/data-model/form_name_mappings.json\"\n",
        "    with open(output_file_path, 'w') as f:\n",
        "        json.dump(mappings, f, indent=4)\n",
        "\n",
        "    print(f\"Mappings saved to {output_file_path}\")\n",
        "\n",
        "    # Print the mappings to the console as well\n",
        "    for key, value in mappings.items():\n",
        "        print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Configuration Setup\n",
        "\n",
        "Configure parameters for the annotation and upload workflow including Synapse authentication, dataset IDs, version labels, and workflow control settings.\n",
        "\n",
        "**IMPORTANT:** Set `DRY_RUN = True` for initial testing to preview changes without uploading.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration Validation:\n",
            "--------------------------------------------------\n",
            "‚úì Synapse-based workflow enabled\n",
            "  - ASSESS staging: syn72119685\n",
            "  - PREVENT staging: syn72119684\n",
            "  - ASSESS release: syn68885185\n",
            "  - PREVENT release: syn68885187\n",
            "‚úì Base directory: /home/ramayyala/Documents/data-model\n",
            "‚úì Data directory: /home/ramayyala/Documents/data-model/data/ALL_ALS/v3-DEC\n",
            "‚úì Annotations directory: /home/ramayyala/Documents/data-model/annotations/all_als\n",
            "‚úì Staging directory: /home/ramayyala/Documents/data-model/staging/all_als\n",
            "‚úì Download directory: /home/ramayyala/Documents/data-model/downloads/all_als\n",
            "‚úì Version: v3-DEC\n",
            "‚úì DRY_RUN mode: False\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ==================== CONFIGURATION ====================\n",
        "# USER: Update these values before running the workflow\n",
        "\n",
        "# Synapse Authentication\n",
        "SYNAPSE_AUTH_TOKEN = \"\"\n",
        "\n",
        "## OLD RELEASE DATASETS (for pulling existing annotations)\n",
        "# Dataset Synapse IDs (existing v2-OCT datasets to pull annotations from)\n",
        "ASSESS_DATASET_SYN_ID = \"syn69694463\"  \n",
        "PREVENT_DATASET_SYN_ID = \"syn69694674\"  \n",
        "\n",
        "# Staging Folders (where contributors upload new file versions)\n",
        "# Set these to empty strings \"\" to fall back to local file workflow\n",
        "ASSESS_STAGING_FOLDER_SYN_ID = \"syn72119685\"  # TODO: Provide ASSESS staging folder syn ID\n",
        "PREVENT_STAGING_FOLDER_SYN_ID = \"syn72119684\"  # TODO: Provide PREVENT staging folder syn ID\n",
        "\n",
        "# Release Folders (where final release files are stored)\n",
        "# Required if staging folders are provided\n",
        "ASSESS_RELEASE_FOLDER_SYN_ID = \"syn68885185\"  # TODO: Provide ASSESS release folder syn ID\n",
        "PREVENT_RELEASE_FOLDER_SYN_ID = \"syn68885187\"  # TODO: Provide PREVENT release folder syn ID\n",
        "\n",
        "# Project ID for uploads\n",
        "SYNAPSE_PROJECT_ID = \"syn68702804\"\n",
        "\n",
        "# Version information\n",
        "VERSION_LABEL = \"v3-DEC\"\n",
        "VERSION_COMMENT = \"Dec Release\"\n",
        "\n",
        "# ==================== AUTO-CONFIGURED PATHS ====================\n",
        "# These paths are automatically configured based on the structure\n",
        "\n",
        "BASE_DIR = \"/home/ramayyala/Documents/data-model\"\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data/ALL_ALS/v3-DEC\")\n",
        "ASSESS_FILES_DIR = os.path.join(DATA_DIR, \"ASSESS/files\")\n",
        "PREVENT_FILES_DIR = os.path.join(DATA_DIR, \"PREVENT/files\")\n",
        "\n",
        "# Model schemas directory\n",
        "SCHEMA_BASE_PATH = os.path.join(BASE_DIR, \"model_schemas\")\n",
        "\n",
        "# Form name mappings (generated by Cell 2)\n",
        "FORM_MAPPINGS_FILE = os.path.join(BASE_DIR, \"form_name_mappings.json\")\n",
        "\n",
        "# Output annotation files\n",
        "ANNOTATIONS_DIR = os.path.join(BASE_DIR, \"annotations/all_als\")\n",
        "os.makedirs(ANNOTATIONS_DIR, exist_ok=True)\n",
        "\n",
        "ASSESS_ANNOTATIONS_FILE = os.path.join(ANNOTATIONS_DIR, \"assess_file_annotations.json\")\n",
        "PREVENT_ANNOTATIONS_FILE = os.path.join(ANNOTATIONS_DIR, \"prevent_file_annotations.json\")\n",
        "ASSESS_DATASET_ANNOTATIONS_FILE = os.path.join(ANNOTATIONS_DIR, \"assess_dataset_annotations.json\")\n",
        "PREVENT_DATASET_ANNOTATIONS_FILE = os.path.join(ANNOTATIONS_DIR, \"prevent_dataset_annotations.json\")\n",
        "\n",
        "# Staging directories for renamed files\n",
        "STAGING_DIR = os.path.join(BASE_DIR, \"staging/all_als\")\n",
        "ASSESS_STAGING_DIR = os.path.join(STAGING_DIR, \"assess\")\n",
        "PREVENT_STAGING_DIR = os.path.join(STAGING_DIR, \"prevent\")\n",
        "os.makedirs(ASSESS_STAGING_DIR, exist_ok=True)\n",
        "os.makedirs(PREVENT_STAGING_DIR, exist_ok=True)\n",
        "\n",
        "# Download directory for Synapse files\n",
        "DOWNLOAD_DIR = os.path.join(BASE_DIR, \"downloads/all_als\")\n",
        "ASSESS_DOWNLOAD_DIR = os.path.join(DOWNLOAD_DIR, \"assess\")\n",
        "PREVENT_DOWNLOAD_DIR = os.path.join(DOWNLOAD_DIR, \"prevent\")\n",
        "os.makedirs(ASSESS_DOWNLOAD_DIR, exist_ok=True)\n",
        "os.makedirs(PREVENT_DOWNLOAD_DIR, exist_ok=True)\n",
        "\n",
        "# ==================== WORKFLOW CONTROL ====================\n",
        "DRY_RUN = False  # Set to False to actually upload files\n",
        "VERBOSE = True  # Set to False for less output\n",
        "\n",
        "# Determine workflow mode\n",
        "USE_SYNAPSE_STAGING = bool(ASSESS_STAGING_FOLDER_SYN_ID and PREVENT_STAGING_FOLDER_SYN_ID)\n",
        "\n",
        "# ==================== VALIDATION ====================\n",
        "print(\"Configuration Validation:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "if not SYNAPSE_AUTH_TOKEN:\n",
        "    print(\"‚ö†Ô∏è  WARNING: SYNAPSE_AUTH_TOKEN not set\")\n",
        "if not ASSESS_DATASET_SYN_ID:\n",
        "    print(\"‚ö†Ô∏è  WARNING: ASSESS_DATASET_SYN_ID not set\")\n",
        "if not PREVENT_DATASET_SYN_ID:\n",
        "    print(\"‚ö†Ô∏è  WARNING: PREVENT_DATASET_SYN_ID not set\")\n",
        "if not SYNAPSE_PROJECT_ID:\n",
        "    print(\"‚ö†Ô∏è  WARNING: SYNAPSE_PROJECT_ID not set\")\n",
        "\n",
        "# Validate staging/release folder configuration\n",
        "if USE_SYNAPSE_STAGING:\n",
        "    print(f\"‚úì Synapse-based workflow enabled\")\n",
        "    if not ASSESS_RELEASE_FOLDER_SYN_ID or not PREVENT_RELEASE_FOLDER_SYN_ID:\n",
        "        print(\"‚ùå ERROR: Release folder IDs required when staging folders are provided\")\n",
        "        print(\"   Please set ASSESS_RELEASE_FOLDER_SYN_ID and PREVENT_RELEASE_FOLDER_SYN_ID\")\n",
        "        raise ValueError(\"Release folder IDs required with staging folders\")\n",
        "    print(f\"  - ASSESS staging: {ASSESS_STAGING_FOLDER_SYN_ID}\")\n",
        "    print(f\"  - PREVENT staging: {PREVENT_STAGING_FOLDER_SYN_ID}\")\n",
        "    print(f\"  - ASSESS release: {ASSESS_RELEASE_FOLDER_SYN_ID}\")\n",
        "    print(f\"  - PREVENT release: {PREVENT_RELEASE_FOLDER_SYN_ID}\")\n",
        "else:\n",
        "    print(f\"‚úì Local file workflow (staging folders not configured)\")\n",
        "\n",
        "print(f\"‚úì Base directory: {BASE_DIR}\")\n",
        "print(f\"‚úì Data directory: {DATA_DIR}\")\n",
        "print(f\"‚úì Annotations directory: {ANNOTATIONS_DIR}\")\n",
        "print(f\"‚úì Staging directory: {STAGING_DIR}\")\n",
        "print(f\"‚úì Download directory: {DOWNLOAD_DIR}\")\n",
        "print(f\"‚úì Version: {VERSION_LABEL}\")\n",
        "print(f\"‚úì DRY_RUN mode: {DRY_RUN}\")\n",
        "print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Library Imports\n",
        "\n",
        "Import required Python libraries for the workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì All libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "import shutil\n",
        "from pprint import pprint\n",
        "\n",
        "# Synapse client\n",
        "import synapseclient\n",
        "from synapseclient.models import (\n",
        "    File, Folder, Project, Table, EntityView, Dataset,\n",
        "    DatasetCollection, MaterializedView, SubmissionView\n",
        ")\n",
        "\n",
        "# Schema handling\n",
        "import yaml\n",
        "from jsonschema import validate, ValidationError, Draft7Validator\n",
        "import re\n",
        "print(\"‚úì All libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Core Utility Functions\n",
        "\n",
        "Define utility functions for Synapse connection, schema loading, annotation cleaning, and validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Core utility functions defined (including Synapse workflow functions)\n"
          ]
        }
      ],
      "source": [
        "# ==================== SYNAPSE CONNECTION ====================\n",
        "\n",
        "def connect_to_synapse():\n",
        "    \"\"\"Connect to Synapse using the configured auth token.\"\"\"\n",
        "    if not SYNAPSE_AUTH_TOKEN:\n",
        "        raise ValueError(\"SYNAPSE_AUTH_TOKEN is not set. Please update configuration.\")\n",
        "\n",
        "    try:\n",
        "        syn = synapseclient.Synapse()\n",
        "        syn.login(authToken=SYNAPSE_AUTH_TOKEN)\n",
        "        print(\"‚úì Successfully connected to Synapse\")\n",
        "        return syn\n",
        "    except Exception as e:\n",
        "        print(f\"‚úó Failed to connect to Synapse: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "# ==================== SCHEMA LOADING ====================\n",
        "\n",
        "def get_all_schemas(schema_base_path=None):\n",
        "    \"\"\"Load all YAML schema files recursively.\"\"\"\n",
        "    if schema_base_path is None:\n",
        "        schema_base_path = SCHEMA_BASE_PATH\n",
        "\n",
        "    schemas = {}\n",
        "    schema_path = Path(schema_base_path)\n",
        "\n",
        "    for yaml_file in schema_path.rglob(\"*.yaml\"):\n",
        "        try:\n",
        "            with open(yaml_file, 'r') as f:\n",
        "                schema_data = yaml.safe_load(f)\n",
        "                if schema_data and isinstance(schema_data, dict):\n",
        "                    # Look for 'classes' key in YAML structure\n",
        "                    if 'classes' in schema_data:\n",
        "                        for class_name, class_def in schema_data['classes'].items():\n",
        "                            if isinstance(class_def, dict):\n",
        "                                schemas[class_name] = class_def\n",
        "                    # Also support old flat structure for backwards compatibility\n",
        "                    else:\n",
        "                        for class_name, class_def in schema_data.items():\n",
        "                            if isinstance(class_def, dict):\n",
        "                                schemas[class_name] = class_def\n",
        "        except Exception as e:\n",
        "            if VERBOSE:\n",
        "                print(f\"Warning: Could not load {yaml_file}: {e}\")\n",
        "\n",
        "    print(f\"‚úì Loaded {len(schemas)} schema definitions\")\n",
        "    return schemas\n",
        "\n",
        "\n",
        "def get_full_schema(class_name, all_schemas, visited=None):\n",
        "    \"\"\"Get full schema for a class including inherited attributes.\"\"\"\n",
        "    if visited is None:\n",
        "        visited = set()\n",
        "\n",
        "    if class_name in visited:\n",
        "        return {}\n",
        "    visited.add(class_name)\n",
        "\n",
        "    if class_name not in all_schemas:\n",
        "        return {}\n",
        "\n",
        "    schema = all_schemas[class_name]\n",
        "    full_attributes = {}\n",
        "\n",
        "    # Process inheritance (is_a)\n",
        "    if 'is_a' in schema:\n",
        "        parent_class = schema['is_a']\n",
        "        parent_attrs = get_full_schema(parent_class, all_schemas, visited)\n",
        "        full_attributes.update(parent_attrs)\n",
        "\n",
        "    # Process mixins\n",
        "    if 'mixins' in schema and isinstance(schema['mixins'], list):\n",
        "        for mixin in schema['mixins']:\n",
        "            mixin_attrs = get_full_schema(mixin, all_schemas, visited)\n",
        "            full_attributes.update(mixin_attrs)\n",
        "\n",
        "    # Add own attributes\n",
        "    if 'attributes' in schema:\n",
        "        full_attributes.update(schema['attributes'])\n",
        "\n",
        "    return full_attributes\n",
        "\n",
        "\n",
        "# ==================== ANNOTATION CLEANING ====================\n",
        "\n",
        "def clean_annotations_for_synapse(annotation):\n",
        "    \"\"\"Remove metadata fields and empty values before applying to Synapse.\"\"\"\n",
        "    cleaned = {}\n",
        "\n",
        "    for key, value in annotation.items():\n",
        "        # Skip metadata fields (starting with _)\n",
        "        if key.startswith('_'):\n",
        "            continue\n",
        "        \n",
        "        # Convert File objects to syn IDs (do this FIRST before any comparisons)\n",
        "        if hasattr(value, '__class__') and value.__class__.__name__ == 'File':\n",
        "            value = value.id if hasattr(value, 'id') else str(value)\n",
        "        \n",
        "        # Handle lists that might contain File objects\n",
        "        elif isinstance(value, list):\n",
        "            cleaned_list = []\n",
        "            for item in value:\n",
        "                if hasattr(item, '__class__') and item.__class__.__name__ == 'File':\n",
        "                    cleaned_list.append(item.id if hasattr(item, 'id') else str(item))\n",
        "                else:\n",
        "                    cleaned_list.append(item)\n",
        "            value = cleaned_list\n",
        "        \n",
        "        # NOW check for truly empty values (after conversion)\n",
        "        if value is None:\n",
        "            continue\n",
        "        if isinstance(value, str) and value == \"\":\n",
        "            continue\n",
        "        if isinstance(value, list) and (len(value) == 0 or (len(value) == 1 and value[0] == \"\")):\n",
        "            continue\n",
        "\n",
        "        cleaned[key] = value\n",
        "\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "# ==================== VALIDATION ====================\n",
        "\n",
        "def validate_annotation_against_schema(annotation, file_type, all_schemas):\n",
        "    \"\"\"Validate a single annotation against its schema.\"\"\"\n",
        "    errors = []\n",
        "    warnings = []\n",
        "\n",
        "    # Get full schema with inheritance\n",
        "    schema_attributes = get_full_schema(file_type, all_schemas)\n",
        "\n",
        "    if not schema_attributes:\n",
        "        errors.append(f\"Schema not found for file type: {file_type}\")\n",
        "        return False, errors, warnings\n",
        "\n",
        "    # Check required fields\n",
        "    for attr_name, attr_def in schema_attributes.items():\n",
        "        is_required = attr_def.get('required', False)\n",
        "\n",
        "        if is_required:\n",
        "            if attr_name not in annotation:\n",
        "                errors.append(f\"Required field missing: {attr_name}\")\n",
        "            elif annotation[attr_name] in [\"\", [\"\"], [], None]:\n",
        "                errors.append(f\"Required field empty: {attr_name}\")\n",
        "\n",
        "    # Check multivalued fields\n",
        "    for attr_name, attr_value in annotation.items():\n",
        "        if attr_name.startswith('_'):\n",
        "            continue\n",
        "\n",
        "        if attr_name in schema_attributes:\n",
        "            attr_def = schema_attributes[attr_name]\n",
        "            is_multivalued = attr_def.get('multivalued', False)\n",
        "\n",
        "            if is_multivalued and not isinstance(attr_value, list):\n",
        "                errors.append(f\"Field {attr_name} should be a list\")\n",
        "            elif not is_multivalued and isinstance(attr_value, list):\n",
        "                warnings.append(f\"Field {attr_name} is a list but should be a single value\")\n",
        "\n",
        "    # Check if at least some fields are filled\n",
        "    filled_fields = sum(1 for k, v in annotation.items()\n",
        "                       if not k.startswith('_') and v not in [\"\", [\"\"], [], None])\n",
        "\n",
        "    if filled_fields == 0:\n",
        "        warnings.append(\"No annotation fields are filled\")\n",
        "\n",
        "    is_valid = len(errors) == 0\n",
        "    return is_valid, errors, warnings\n",
        "\n",
        "\n",
        "# ==================== NEW SYNAPSE-BASED WORKFLOW FUNCTIONS ====================\n",
        "\n",
        "def enumerate_folder_files(syn, folder_syn_id):\n",
        "    \"\"\"\n",
        "    Query all files in a Synapse folder and extract their annotations.\n",
        "    \n",
        "    Args:\n",
        "        syn: Synapse client\n",
        "        folder_syn_id: Synapse ID of the folder\n",
        "    \n",
        "    Returns: {syn_id: {filename: {annotations}}}\n",
        "    \"\"\"\n",
        "    print(f\"Retrieving files from folder {folder_syn_id}...\")\n",
        "    \n",
        "    try:\n",
        "        # Query for all files in the folder\n",
        "        query_results = list(syn.getChildren(folder_syn_id, includeTypes=[\"file\"]))\n",
        "        \n",
        "        annotations_dict = {}\n",
        "        file_count = 0\n",
        "        \n",
        "        for item in query_results:\n",
        "            syn_id = item['id']\n",
        "            filename = item['name']\n",
        "            \n",
        "            # Get annotations for this file\n",
        "            try:\n",
        "                entity = syn.get(syn_id, downloadFile=False)\n",
        "                annotations = dict(entity.annotations) if hasattr(entity, 'annotations') else {}\n",
        "                \n",
        "                if annotations or True:  # Include all files even without annotations\n",
        "                    annotations_dict[syn_id] = {filename: annotations}\n",
        "                    file_count += 1\n",
        "                    \n",
        "            except Exception as e:\n",
        "                if VERBOSE:\n",
        "                    print(f\"  ‚ö†Ô∏è  Could not get annotations for {filename}: {e}\")\n",
        "        \n",
        "        print(f\"‚úì Retrieved {file_count} files from folder\")\n",
        "        return annotations_dict\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚úó Error retrieving folder files: {e}\")\n",
        "        return {}\n",
        "\n",
        "\n",
        "def download_synapse_file(syn, file_syn_id, download_dir):\n",
        "    \"\"\"\n",
        "    Download a file from Synapse to local directory.\n",
        "    \n",
        "    Args:\n",
        "        syn: Synapse client\n",
        "        file_syn_id: Synapse ID of the file\n",
        "        download_dir: Local directory to download to\n",
        "    \n",
        "    Returns: Local file path or None if error\n",
        "    \"\"\"\n",
        "    try:\n",
        "        entity = syn.get(file_syn_id, downloadLocation=download_dir)\n",
        "        local_path = entity.path\n",
        "        \n",
        "        if VERBOSE:\n",
        "            print(f\"  ‚úì Downloaded {entity.name} to {local_path}\")\n",
        "        \n",
        "        return local_path\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  ‚úó Error downloading {file_syn_id}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def merge_file_annotations(old_annot, new_annot, template):\n",
        "    \"\"\"\n",
        "    Merge annotations with priority: old (release) > new (staging) > template.\n",
        "    \n",
        "    Args:\n",
        "        old_annot: Annotations from release version (highest priority)\n",
        "        new_annot: Annotations from staging version\n",
        "        template: Template with all schema fields\n",
        "    \n",
        "    Returns: Merged annotation dict\n",
        "    \"\"\"\n",
        "    merged = {}\n",
        "    \n",
        "    # Start with template to ensure all fields are present\n",
        "    merged.update(template)\n",
        "    \n",
        "    # Add new staging annotations (overwrite template)\n",
        "    for key, value in new_annot.items():\n",
        "        if value not in [\"\", [\"\"], [], None]:\n",
        "            merged[key] = value\n",
        "    \n",
        "    # Add old release annotations (overwrite template and new - highest priority)\n",
        "    for key, value in old_annot.items():\n",
        "        if value not in [\"\", [\"\"], [], None]:\n",
        "            merged[key] = value\n",
        "    \n",
        "    return merged\n",
        "\n",
        "\n",
        "def move_file_to_release(syn, file_syn_id, release_folder_syn_id, dataset_syn_id, annotations, form_name, dry_run=True):\n",
        "    \"\"\"\n",
        "    Move file from staging folder to release folder, add to dataset, and set annotations.\n",
        "    \n",
        "    Args:\n",
        "        syn: Synapse client\n",
        "        file_syn_id: Synapse ID of file to move\n",
        "        release_folder_syn_id: Synapse ID of release folder (destination)\n",
        "        dataset_syn_id: Synapse ID of dataset to add file to\n",
        "        annotations: Annotations to apply to the file\n",
        "        form_name: Form name to rename the file to (e.g., \"Demographics\")\n",
        "        dry_run: If True, only preview the operation\n",
        "    \n",
        "    Returns: (success, error_message)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get file entity info\n",
        "        file_entity = syn.get(file_syn_id, downloadFile=False)\n",
        "        filename = file_entity.name\n",
        "        \n",
        "        if dry_run:\n",
        "            print(f\"  [DRY_RUN] Would move {filename}:\")\n",
        "            print(f\"    - From: current folder ‚Üí {release_folder_syn_id}\")\n",
        "            print(f\"    - Rename to: {form_name}.csv\")\n",
        "            print(f\"    - Add to dataset: {dataset_syn_id}\")\n",
        "            print(f\"    - Set annotations: {len(clean_annotations_for_synapse(annotations))} fields\")\n",
        "            return (True, None)\n",
        "        \n",
        "        # Step 1: Move file to release folder\n",
        "        try:\n",
        "            syn.move(file_syn_id, release_folder_syn_id)\n",
        "            if VERBOSE:\n",
        "                print(f\"  ‚úì Moved {filename} to release folder\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Failed to move file: {e}\")\n",
        "        \n",
        "        # Step 1.5: Rename file using form name\n",
        "        try:\n",
        "            file_entity = syn.get(file_syn_id, downloadFile=False)\n",
        "            original_filename = file_entity.name\n",
        "            # Sanitize the form name to comply with Synapse naming rules\n",
        "            sanitized_form_name = sanitize_synapse_filename(form_name)\n",
        "            new_filename = f\"{sanitized_form_name}.csv\"\n",
        "            \n",
        "            if original_filename != new_filename:\n",
        "                file_entity.name = new_filename\n",
        "                syn.store(file_entity, forceVersion=False)\n",
        "                if VERBOSE:\n",
        "                    print(f\"  ‚úì Renamed {original_filename} ‚Üí {new_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ö†Ô∏è  Warning: Could not rename file: {e}\")\n",
        "            # Don't fail - file is already moved\n",
        "        \n",
        "        # Step 2: Add file to dataset\n",
        "        try:\n",
        "            dataset = Dataset(dataset_syn_id).get()\n",
        "            # Add file to dataset items\n",
        "            from synapseclient.models import File as FileModel\n",
        "            file_to_add = FileModel(id=file_syn_id)\n",
        "            dataset.add_item(file_to_add)\n",
        "            dataset.store()\n",
        "            if VERBOSE:\n",
        "                print(f\"  ‚úì Added {filename} to dataset\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ö†Ô∏è  Warning: Could not add to dataset: {e}\")\n",
        "            # Don't fail - file is already moved\n",
        "        \n",
        "        # Step 3: Set annotations on the moved file\n",
        "        try:\n",
        "            # Re-fetch the file entity after move to avoid 412 conflict\n",
        "            file_entity = syn.get(file_syn_id, downloadFile=False)\n",
        "            cleaned_annotations = clean_annotations_for_synapse(annotations)\n",
        "            file_entity.annotations = cleaned_annotations\n",
        "            syn.store(file_entity, forceVersion=False)\n",
        "            if VERBOSE:\n",
        "                print(f\"  ‚úì Set annotations on {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ö†Ô∏è  Warning: Could not set annotations: {e}\")\n",
        "            # Don't fail - file is moved and in dataset\n",
        "        \n",
        "        return (True, None)\n",
        "        \n",
        "    except Exception as e:\n",
        "        # Handle case where filename isn't set yet\n",
        "        file_desc = filename if 'filename' in locals() else file_syn_id\n",
        "        error_msg = f\"Failed to move {file_desc}: {e}\"\n",
        "        print(f\"  ‚úó {error_msg}\")\n",
        "        return (False, error_msg)\n",
        "\n",
        "\n",
        "print(\"‚úì Core utility functions defined (including Synapse workflow functions)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Retrieve Existing Annotations from Synapse\n",
        "\n",
        "Pull existing annotations from ASSESS and PREVENT dataset entities. This retrieves annotations from v2-OCT datasets to understand what files already exist and their current metadata.\n",
        "\n",
        "**Output Structure:** `{syn_id: {file_name: {annotations}}}`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "RETRIEVING EXISTING ANNOTATIONS FROM SYNAPSE\n",
            "============================================================\n",
            "\n",
            "UPGRADE AVAILABLE\n",
            "\n",
            "A more recent version of the Synapse Client (4.10.0) is available. Your version (4.8.0) can be upgraded by typing:\n",
            "   pip install --upgrade synapseclient\n",
            "\n",
            "Python Synapse Client version 4.10.0 release notes\n",
            "\n",
            "https://python-docs.synapse.org/news/\n",
            "\n",
            "\n",
            "Welcome, ram.ayyala!\n",
            "\n",
            "‚úì Successfully connected to Synapse\n",
            "\n",
            "--- RELEASE DATASETS (Old Versions) ---\n",
            "\n",
            "ASSESS Dataset:\n",
            "Retrieving files from dataset syn69694463...\n",
            "‚úì Retrieved annotations for 32 files\n",
            "\n",
            "PREVENT Dataset:\n",
            "Retrieving files from dataset syn69694674...\n",
            "‚úì Retrieved annotations for 49 files\n",
            "\n",
            "--- STAGING FOLDERS (New Versions) ---\n",
            "\n",
            "ASSESS Staging Folder:\n",
            "Retrieving files from folder syn72119685...\n",
            "‚úì Retrieved 32 files from folder\n",
            "\n",
            "PREVENT Staging Folder:\n",
            "Retrieving files from folder syn72119684...\n",
            "‚úì Retrieved 50 files from folder\n",
            "\n",
            "============================================================\n",
            "RETRIEVAL SUMMARY\n",
            "============================================================\n",
            "ASSESS:\n",
            "  - Release files: 32\n",
            "  - Staging files: 32\n",
            "  - Dataset annotations: 12 fields\n",
            "\n",
            "PREVENT:\n",
            "  - Release files: 49\n",
            "  - Staging files: 50\n",
            "  - Dataset annotations: 11 fields\n",
            "\n",
            "Workflow mode: Synapse-based\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "def get_existing_synapse_annotations(syn, entity_id):\n",
        "    \"\"\"Get annotations from a single Synapse entity.\"\"\"\n",
        "    try:\n",
        "        entity = syn.get(entity_id, downloadFile=False)\n",
        "        return [entity.name,dict(entity.annotations)]\n",
        "    except Exception as e:\n",
        "        if VERBOSE:\n",
        "            print(f\"Warning: Could not get annotations for {entity_id}: {e}\")\n",
        "        return {}\n",
        "\n",
        "def enumerate_dataset_files(syn, dataset_syn_id):\n",
        "    \"\"\"\n",
        "    Query all files in a dataset and extract their annotations.\n",
        "    Returns: {syn_id: {filename: {annotations}}}\n",
        "    \"\"\"\n",
        "    print(f\"Retrieving files from dataset {dataset_syn_id}...\")\n",
        "\n",
        "    try:\n",
        "        # Get the dataset entity\n",
        "        dataset = Dataset(dataset_syn_id).get()\n",
        "        results=dataset.items\n",
        "        annotations_dict = {}\n",
        "        file_count = 0\n",
        "\n",
        "        for row in results:\n",
        "             syn_id=row.id\n",
        "            # Get annotations for this file\n",
        "             results = get_existing_synapse_annotations(syn, syn_id)\n",
        "             filename=results[0]\n",
        "             annotations=results[1]\n",
        "             if annotations:\n",
        "                annotations_dict[syn_id] = {filename: annotations}\n",
        "                file_count += 1\n",
        "\n",
        "        print(f\"‚úì Retrieved annotations for {file_count} files\")\n",
        "        return annotations_dict\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚úó Error retrieving dataset files: {e}\")\n",
        "        print(\"Note: Make sure you have provided a valid dataset syn ID\")\n",
        "        return {}\n",
        "\n",
        "\n",
        "def get_dataset_annotations(syn, dataset_syn_id):\n",
        "    \"\"\"Get annotations from the dataset entity itself.\"\"\"\n",
        "    try:\n",
        "        dataset = syn.get(dataset_syn_id, downloadFile=False)\n",
        "        return dict(dataset.annotations) if hasattr(dataset, 'annotations') and dataset.annotations else {}\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Could not get dataset annotations: {e}\")\n",
        "        return {}\n",
        "\n",
        "\n",
        "# Connect to Synapse\n",
        "print(\"=\" * 60)\n",
        "print(\"RETRIEVING EXISTING ANNOTATIONS FROM SYNAPSE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if not ASSESS_DATASET_SYN_ID or not PREVENT_DATASET_SYN_ID:\n",
        "    print(\"‚ö†Ô∏è  Skipping: Dataset syn IDs not configured\")\n",
        "    print(\"Please update ASSESS_DATASET_SYN_ID and PREVENT_DATASET_SYN_ID in the configuration cell\")\n",
        "    assess_existing_annotations = {}\n",
        "    prevent_existing_annotations = {}\n",
        "    assess_dataset_existing_annotations = {}\n",
        "    prevent_dataset_existing_annotations = {}\n",
        "    assess_staging_files = {}\n",
        "    prevent_staging_files = {}\n",
        "else:\n",
        "    syn = connect_to_synapse()\n",
        "\n",
        "    print(\"\\n--- RELEASE DATASETS (Old Versions) ---\")\n",
        "    print(\"\\nASSESS Dataset:\")\n",
        "    # Get file annotations from release dataset\n",
        "    assess_existing_annotations = enumerate_dataset_files(syn, ASSESS_DATASET_SYN_ID)\n",
        "    # Get dataset entity annotations\n",
        "    assess_dataset_existing_annotations = get_dataset_annotations(syn, ASSESS_DATASET_SYN_ID)\n",
        "\n",
        "    print(\"\\nPREVENT Dataset:\")\n",
        "    # Get file annotations from release dataset\n",
        "    prevent_existing_annotations = enumerate_dataset_files(syn, PREVENT_DATASET_SYN_ID)\n",
        "    # Get dataset entity annotations\n",
        "    prevent_dataset_existing_annotations = get_dataset_annotations(syn, PREVENT_DATASET_SYN_ID)\n",
        "\n",
        "    # Retrieve from staging folders if configured\n",
        "    if USE_SYNAPSE_STAGING:\n",
        "        print(\"\\n--- STAGING FOLDERS (New Versions) ---\")\n",
        "        \n",
        "        print(\"\\nASSESS Staging Folder:\")\n",
        "        assess_staging_files = enumerate_folder_files(syn, ASSESS_STAGING_FOLDER_SYN_ID)\n",
        "        \n",
        "        print(\"\\nPREVENT Staging Folder:\")\n",
        "        prevent_staging_files = enumerate_folder_files(syn, PREVENT_STAGING_FOLDER_SYN_ID)\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è  Staging folders not configured - using local file workflow\")\n",
        "        assess_staging_files = {}\n",
        "        prevent_staging_files = {}\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"RETRIEVAL SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"ASSESS:\")\n",
        "    print(f\"  - Release files: {len(assess_existing_annotations)}\")\n",
        "    print(f\"  - Staging files: {len(assess_staging_files)}\")\n",
        "    print(f\"  - Dataset annotations: {len(assess_dataset_existing_annotations)} fields\")\n",
        "    print(f\"\\nPREVENT:\")\n",
        "    print(f\"  - Release files: {len(prevent_existing_annotations)}\")\n",
        "    print(f\"  - Staging files: {len(prevent_staging_files)}\")\n",
        "    print(f\"  - Dataset annotations: {len(prevent_dataset_existing_annotations)} fields\")\n",
        "    print(f\"\\nWorkflow mode: {'Synapse-based' if USE_SYNAPSE_STAGING else 'Local files'}\")\n",
        "    print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Compare Local Files with Existing Annotations\n",
        "\n",
        "Compare local v3-DEC files with existing Synapse annotations to identify:\n",
        "1. **Matched files**: Exist in Synapse (will be updated with new versions)\n",
        "2. **Unmatched files**: New files needing annotation templates\n",
        "\n",
        "Matching uses form_name_mappings.json to normalize filenames.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MATCHING FILES (THREE-WAY)\n",
            "============================================================\n",
            "‚úì Loaded 82 form name mappings\n",
            "\n",
            "Scanning local files...\n",
            "‚úì Found 32 ASSESS local files\n",
            "‚úì Found 50 PREVENT local files\n",
            "\n",
            "Performing three-way matching...\n",
            "Mode: Synapse staging ‚Üí release ‚Üí local\n",
            "\n",
            "\n",
            "============================================================\n",
            "MATCHING RESULTS\n",
            "============================================================\n",
            "ASSESS:\n",
            "  - Matched (will update): 30 files\n",
            "  - New files (need move/create): 2 files\n",
            "  - In release but not staging: 4 files (will skip)\n",
            "\n",
            "PREVENT:\n",
            "  - Matched (will update): 42 files\n",
            "  - New files (need move/create): 8 files\n",
            "  - In release but not staging: 9 files (will skip)\n",
            "\n",
            "üìÅ  New ASSESS files:\n",
            "  - v_ALLALS_AS_ASSEICFCSF.csv (syn71824528) ‚Üí will MOVE to release\n",
            "  - v_ALLALS_AS_NPROREGASSESS.csv (syn71824537) ‚Üí will MOVE to release\n",
            "\n",
            "üìÅ  New PREVENT files:\n",
            "  - v_ALLALS_PR_NPROREG.csv (syn71824458) ‚Üí will MOVE to release\n",
            "  - v_ALLALS_PR_PREVFUTELEV.csv (syn71824478) ‚Üí will MOVE to release\n",
            "  - v_ALLALS_PR_PREVHHD.csv (syn71824485) ‚Üí will MOVE to release\n",
            "  - v_ALLALS_PR_PREVICFGEN.csv (syn71824484) ‚Üí will MOVE to release\n",
            "  - v_ALLALS_PR_PREVOGCVH.csv (syn71824493) ‚Üí will MOVE to release\n",
            "  - v_ALLALS_PR_PREVPREGENCONAP.csv (syn71824499) ‚Üí will MOVE to release\n",
            "  - v_ALLALS_PR_PREVPSTGENCONAP.csv (syn71824500) ‚Üí will MOVE to release\n",
            "  - v_ALLALS_PR_PREVVITSIGN.csv (syn71824506) ‚Üí will MOVE to release\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "def load_form_name_mappings():\n",
        "    \"\"\"Load the form_name_mappings.json file.\"\"\"\n",
        "    if not os.path.exists(FORM_MAPPINGS_FILE):\n",
        "        print(f\"‚ö†Ô∏è  Warning: {FORM_MAPPINGS_FILE} not found\")\n",
        "        print(\"Please run Cell 2 to generate the mapping file\")\n",
        "        return {}\n",
        "\n",
        "    with open(FORM_MAPPINGS_FILE, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "def get_local_files(directory):\n",
        "    \"\"\"Get list of CSV files in directory with full paths.\"\"\"\n",
        "    if not os.path.isdir(directory):\n",
        "        print(f\"‚ö†Ô∏è  Warning: Directory not found: {directory}\")\n",
        "        return []\n",
        "\n",
        "    files = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".csv\"):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            files.append((filename, file_path))\n",
        "\n",
        "    return files\n",
        "\n",
        "\n",
        "def extract_clean_filename(filename):\n",
        "    \"\"\"Remove v_ALLALS_XX_ prefix from filename.\"\"\"\n",
        "    clean = filename.replace('v_ALLALS_AS_', '').replace('v_ALLALS_PV_', '').replace('v_ALLALS_PR_', '')\n",
        "    clean = os.path.splitext(clean)[0]  # Remove .csv extension\n",
        "    clean = clean.replace('-', '_')\n",
        "    return clean\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def sanitize_synapse_filename(filename):\n",
        "    \"\"\"\n",
        "    Sanitize filename to comply with Synapse naming rules.\n",
        "    \n",
        "    Synapse allows only: letters, numbers, spaces, underscores, hyphens, \n",
        "    periods, plus signs, apostrophes, and parenthesis.\n",
        "    \n",
        "    Args:\n",
        "        filename: Original filename\n",
        "    \n",
        "    Returns:\n",
        "        Sanitized filename safe for Synapse\n",
        "    \"\"\"\n",
        "    # Replace common problematic characters with safe alternatives\n",
        "    replacements = {\n",
        "        ':': '-',  # Colon to hyphen\n",
        "        '/': '-',  # Slash to hyphen\n",
        "        '\\\\': '-',  # Backslash to hyphen\n",
        "        '|': '-',  # Pipe to hyphen\n",
        "        '*': '',   # Asterisk removed\n",
        "        '?': '',   # Question mark removed\n",
        "        '\"': \"'\",  # Double quote to single quote\n",
        "        '<': '(',  # Less than to open paren\n",
        "        '>': ')',  # Greater than to close paren\n",
        "    }\n",
        "    \n",
        "    sanitized = filename\n",
        "    for old_char, new_char in replacements.items():\n",
        "        sanitized = sanitized.replace(old_char, new_char)\n",
        "    \n",
        "    # Remove any remaining characters that aren't allowed\n",
        "    # Allowed: letters, numbers, spaces, _-.()+' and ()\n",
        "    sanitized = re.sub(r\"[^a-zA-Z0-9 _\\\\-\\\\.\\\\+\\'\\\\(\\\\)]\", \"\", sanitized)\n",
        "    \n",
        "    # Clean up multiple spaces or hyphens in a row\n",
        "    sanitized = re.sub(r' +', ' ', sanitized)\n",
        "    sanitized = re.sub(r'-+', '-', sanitized)\n",
        "    \n",
        "    # Remove leading/trailing spaces and hyphens\n",
        "    sanitized = sanitized.strip(' -')\n",
        "    \n",
        "    return sanitized\n",
        "\n",
        "def match_three_way(staging_files, release_files, local_files, form_mappings, dataset_prefix=None):\n",
        "    \"\"\"\n",
        "    Three-way matching: staging ‚Üî release ‚Üî local (fallback).\n",
        "    \n",
        "    Args:\n",
        "        staging_files: {syn_id: {filename: {annotations}}} from staging folder\n",
        "        release_files: {syn_id: {filename: {annotations}}} from release dataset\n",
        "        local_files: [(filename, path)] from local directory\n",
        "        form_mappings: {clean_filename: form_name}\n",
        "        dataset_prefix: Optional prefix to filter form_mappings (e.g., \"ASSE\" or \"PREV\")\n",
        "    \n",
        "    Returns:\n",
        "        matched: List[(staging_syn_id, release_syn_id, local_path, form_name)]\n",
        "        new_only: List[(staging_syn_id, staging_filename, form_name)]\n",
        "        no_staging: List[(release_syn_id, release_filename)]\n",
        "    \"\"\"\n",
        "    matched = []\n",
        "    new_only = []\n",
        "    no_staging = []\n",
        "    \n",
        "    # Filter form_mappings by dataset prefix if provided\n",
        "    if dataset_prefix:\n",
        "        filtered_mappings = {k: v for k, v in form_mappings.items() if k.startswith(dataset_prefix)}\n",
        "        if not filtered_mappings:\n",
        "            print(f\"‚ö†Ô∏è  Warning: No form mappings found for prefix '{dataset_prefix}'\")\n",
        "            filtered_mappings = form_mappings\n",
        "    else:\n",
        "        filtered_mappings = form_mappings\n",
        "    \n",
        "    # Create lookup: form_name ‚Üí (release_syn_id, release_filename)\n",
        "    form_name_to_release = {}\n",
        "    for release_syn_id, file_data in release_files.items():\n",
        "        for release_filename in file_data.keys():\n",
        "            # Remove .csv extension and sanitize for comparison\n",
        "            release_base = release_filename.replace('.csv', '').replace('.CSV', '')\n",
        "            release_sanitized = sanitize_synapse_filename(release_base)\n",
        "            # Normalize for comparison (treat hyphens and underscores the same)\n",
        "            release_normalized = release_sanitized.replace('_', '-').lower().strip()\n",
        "            \n",
        "            # Try to match by form name\n",
        "            for clean_key, form_name in filtered_mappings.items():\n",
        "                form_sanitized = sanitize_synapse_filename(form_name)\n",
        "                form_normalized = form_sanitized.replace('_', '-').lower().strip()\n",
        "                \n",
        "                # Try exact match after normalization\n",
        "                if (release_normalized == form_normalized or \n",
        "                    release_sanitized == form_sanitized or \n",
        "                    release_base == form_name or \n",
        "                    release_filename == f\"{form_name}.csv\" or\n",
        "                    clean_key in release_filename):\n",
        "                    form_name_to_release[form_name] = (release_syn_id, release_filename)\n",
        "                    break\n",
        "    \n",
        "    # Create lookup: form_name ‚Üí (local_filename, local_path)\n",
        "    form_name_to_local = {}\n",
        "    for local_filename, local_path in local_files:\n",
        "        clean_name = extract_clean_filename(local_filename)\n",
        "        form_name = filtered_mappings.get(clean_name, clean_name)\n",
        "        form_name_to_local[form_name] = (local_filename, local_path)\n",
        "    \n",
        "    # If we have staging files, match them to release\n",
        "    if staging_files:\n",
        "        # Track which release files we've matched\n",
        "        matched_release_syn_ids = set()\n",
        "        \n",
        "        for staging_syn_id, file_data in staging_files.items():\n",
        "            for staging_filename in file_data.keys():\n",
        "                # Extract form name from staging filename\n",
        "                clean_name = extract_clean_filename(staging_filename)\n",
        "                form_name = filtered_mappings.get(clean_name, clean_name)\n",
        "                \n",
        "                # Try to find match in release\n",
        "                if form_name in form_name_to_release:\n",
        "                    release_syn_id, release_filename = form_name_to_release[form_name]\n",
        "                    matched_release_syn_ids.add(release_syn_id)\n",
        "                    \n",
        "                    # Get local path (may be None if not in local)\n",
        "                    local_path = None\n",
        "                    if form_name in form_name_to_local:\n",
        "                        _, local_path = form_name_to_local[form_name]\n",
        "                    \n",
        "                    matched.append((staging_syn_id, release_syn_id, local_path, form_name))\n",
        "                else:\n",
        "                    # File in staging but not in release - needs to be moved\n",
        "                    new_only.append((staging_syn_id, staging_filename, form_name))\n",
        "        \n",
        "        # Find release files with no staging match\n",
        "        for release_syn_id, file_data in release_files.items():\n",
        "            if release_syn_id not in matched_release_syn_ids:\n",
        "                for release_filename in file_data.keys():\n",
        "                    no_staging.append((release_syn_id, release_filename))\n",
        "    \n",
        "    else:\n",
        "        # Fallback to local file matching (original workflow)\n",
        "        for local_filename, local_path in local_files:\n",
        "            clean_name = extract_clean_filename(local_filename)\n",
        "            form_name = filtered_mappings.get(clean_name, clean_name)\n",
        "            \n",
        "            # Try to find match in release\n",
        "            if form_name in form_name_to_release:\n",
        "                release_syn_id, release_filename = form_name_to_release[form_name]\n",
        "                # Use None for staging_syn_id to indicate local-only workflow\n",
        "                matched.append((None, release_syn_id, local_path, form_name))\n",
        "            else:\n",
        "                # New file (no staging_syn_id, no release_syn_id)\n",
        "                new_only.append((None, local_filename, form_name))\n",
        "    \n",
        "    return matched, new_only, no_staging\n",
        "\n",
        "\n",
        "# Load form name mappings\n",
        "print(\"=\" * 60)\n",
        "print(\"MATCHING FILES (THREE-WAY)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "form_mappings = load_form_name_mappings()\n",
        "print(f\"‚úì Loaded {len(form_mappings)} form name mappings\\n\")\n",
        "\n",
        "# Get local files\n",
        "print(\"Scanning local files...\")\n",
        "assess_local_files = get_local_files(ASSESS_FILES_DIR)\n",
        "prevent_local_files = get_local_files(PREVENT_FILES_DIR)\n",
        "\n",
        "print(f\"‚úì Found {len(assess_local_files)} ASSESS local files\")\n",
        "print(f\"‚úì Found {len(prevent_local_files)} PREVENT local files\\n\")\n",
        "\n",
        "# Three-way matching\n",
        "print(\"Performing three-way matching...\")\n",
        "print(f\"Mode: {'Synapse staging ‚Üí release ‚Üí local' if USE_SYNAPSE_STAGING else 'Local ‚Üí release'}\\n\")\n",
        "\n",
        "assess_matched, assess_new_only, assess_no_staging = match_three_way(\n",
        "    assess_staging_files, assess_existing_annotations, assess_local_files, form_mappings, \"ASSE\"\n",
        ")\n",
        "\n",
        "prevent_matched, prevent_new_only, prevent_no_staging = match_three_way(\n",
        "    prevent_staging_files, prevent_existing_annotations, prevent_local_files, form_mappings, \"PREV\"\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MATCHING RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"ASSESS:\")\n",
        "print(f\"  - Matched (will update): {len(assess_matched)} files\")\n",
        "print(f\"  - New files (need move/create): {len(assess_new_only)} files\")\n",
        "if USE_SYNAPSE_STAGING:\n",
        "    print(f\"  - In release but not staging: {len(assess_no_staging)} files (will skip)\")\n",
        "\n",
        "print(f\"\\nPREVENT:\")\n",
        "print(f\"  - Matched (will update): {len(prevent_matched)} files\")\n",
        "print(f\"  - New files (need move/create): {len(prevent_new_only)} files\")\n",
        "if USE_SYNAPSE_STAGING:\n",
        "    print(f\"  - In release but not staging: {len(prevent_no_staging)} files (will skip)\")\n",
        "\n",
        "if assess_new_only:\n",
        "    print(f\"\\n{'üìÅ' if USE_SYNAPSE_STAGING else '‚ö†Ô∏è'}  New ASSESS files:\")\n",
        "    for staging_syn_id, filename, form_name in assess_new_only:\n",
        "        if staging_syn_id:\n",
        "            print(f\"  - {filename} ({staging_syn_id}) ‚Üí will MOVE to release\")\n",
        "        else:\n",
        "            print(f\"  - {filename} ‚Üí will CREATE (needs syn ID)\")\n",
        "\n",
        "if prevent_new_only:\n",
        "    print(f\"\\n{'üìÅ' if USE_SYNAPSE_STAGING else '‚ö†Ô∏è'}  New PREVENT files:\")\n",
        "    for staging_syn_id, filename, form_name in prevent_new_only:\n",
        "        if staging_syn_id:\n",
        "            print(f\"  - {filename} ({staging_syn_id}) ‚Üí will MOVE to release\")\n",
        "        else:\n",
        "            print(f\"  - {filename} ‚Üí will CREATE (needs syn ID)\")\n",
        "\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Generate Annotation Templates\n",
        "\n",
        "Generate annotation JSON files for manual editing:\n",
        "- **File annotations**: `{syn_id: {file_name: {annotations}}}`\n",
        "- **Dataset annotations**: Flat dictionary\n",
        "\n",
        "For matched files: Uses existing syn_id and merges with schema templates\n",
        "For new files: Uses placeholder \"NEW_{clean_filename}\" as syn_id\n",
        "\n",
        "**User will manually edit these files in the next step.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "GENERATING ANNOTATION TEMPLATES\n",
            "============================================================\n",
            "\n",
            "Generating ASSESS file annotations...\n",
            "‚úì Loaded 54 schema definitions\n",
            "‚úì Generated /home/ramayyala/Documents/data-model/annotations/all_als/assess_file_annotations.json\n",
            "  - 30 matched files (with merged annotations)\n",
            "  - 2 new files\n",
            "\n",
            "Generating PREVENT file annotations...\n",
            "‚úì Loaded 54 schema definitions\n",
            "‚úì Generated /home/ramayyala/Documents/data-model/annotations/all_als/prevent_file_annotations.json\n",
            "  - 42 matched files (with merged annotations)\n",
            "  - 8 new files\n",
            "\n",
            "Generating dataset annotation templates...\n",
            "‚úì Loaded 54 schema definitions\n",
            "‚úì Generated /home/ramayyala/Documents/data-model/annotations/all_als/assess_dataset_annotations.json\n",
            "  - Merged 12 existing fields into template\n",
            "‚úì Loaded 54 schema definitions\n",
            "‚úì Generated /home/ramayyala/Documents/data-model/annotations/all_als/prevent_dataset_annotations.json\n",
            "  - Merged 11 existing fields into template\n",
            "\n",
            "============================================================\n",
            "ANNOTATION FILES CREATED\n",
            "============================================================\n",
            "Files created in: /home/ramayyala/Documents/data-model/annotations/all_als\n",
            "  - assess_file_annotations.json\n",
            "  - prevent_file_annotations.json\n",
            "  - assess_dataset_annotations.json\n",
            "  - prevent_dataset_annotations.json\n",
            "\n",
            "Annotation merging strategy:\n",
            "  Priority: Release > Staging > Template\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "def create_file_annotation_template(file_type='ClinicalFile'):\n",
        "    \"\"\"Generate empty annotation template from schema.\"\"\"\n",
        "    all_schemas = get_all_schemas()\n",
        "    schema_attributes = get_full_schema(file_type, all_schemas)\n",
        "\n",
        "    template = {}\n",
        "    for attr_name, attr_def in schema_attributes.items():\n",
        "        if attr_def.get('multivalued', False):\n",
        "            template[attr_name] = ['']\n",
        "        else:\n",
        "            template[attr_name] = ''\n",
        "\n",
        "    template['_file_type'] = file_type\n",
        "    template['_schema_source'] = 'data-model'\n",
        "    template['_created_timestamp'] = datetime.now().isoformat()\n",
        "\n",
        "    return template\n",
        "\n",
        "\n",
        "def create_dataset_annotation_template(dataset_type='ClinicalDataset'):\n",
        "    \"\"\"Generate empty dataset annotation template from schema.\"\"\"\n",
        "    all_schemas = get_all_schemas()\n",
        "    schema_attributes = get_full_schema(dataset_type, all_schemas)\n",
        "\n",
        "    template = {}\n",
        "    for attr_name, attr_def in schema_attributes.items():\n",
        "        if attr_def.get('multivalued', False):\n",
        "            template[attr_name] = ['']\n",
        "        else:\n",
        "            template[attr_name] = ''\n",
        "\n",
        "    template['_dataset_type'] = dataset_type\n",
        "    template['_schema_source'] = 'data-model'\n",
        "    template['_created_timestamp'] = datetime.now().isoformat()\n",
        "\n",
        "    return template\n",
        "\n",
        "\n",
        "def merge_annotations_into_template(template, existing_annotations):\n",
        "    \"\"\"\n",
        "    Merge existing Synapse annotations into a template.\n",
        "\n",
        "    Args:\n",
        "        template: Template dict with all schema fields\n",
        "        existing_annotations: Existing annotations from Synapse\n",
        "\n",
        "    Returns:\n",
        "        Merged dict with existing values preserved and template fields for missing values\n",
        "    \"\"\"\n",
        "    # Start with existing annotations to preserve all current values\n",
        "    merged = existing_annotations.copy()\n",
        "\n",
        "    # Add any template fields that don't exist in existing annotations\n",
        "    for key, value in template.items():\n",
        "        if key not in merged:\n",
        "            merged[key] = value\n",
        "\n",
        "    return merged\n",
        "\n",
        "\n",
        "def generate_annotation_files_with_merging(\n",
        "    matched, new_only, \n",
        "    release_annotations, staging_annotations,\n",
        "    output_file, dataset_name\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate annotation JSON files with three-way merging: release > staging > template.\n",
        "\n",
        "    Args:\n",
        "        matched: List of (staging_syn_id, release_syn_id, local_path, form_name)\n",
        "        new_only: List of (staging_syn_id, filename, form_name)\n",
        "        release_annotations: Dict of {syn_id: {filename: {annotations}}} from release\n",
        "        staging_annotations: Dict of {syn_id: {filename: {annotations}}} from staging\n",
        "        output_file: Path to output JSON file\n",
        "        dataset_name: Name of dataset (for display)\n",
        "    \"\"\"\n",
        "    annotations_dict = {}\n",
        "    template = create_file_annotation_template('ClinicalFile')\n",
        "\n",
        "    # Process matched files (merge annotations)\n",
        "    for staging_syn_id, release_syn_id, local_path, form_name in matched:\n",
        "        # Get release annotations (highest priority)\n",
        "        old_annot = {}\n",
        "        if release_syn_id in release_annotations:\n",
        "            release_file_data = release_annotations[release_syn_id]\n",
        "            old_annot = list(release_file_data.values())[0]\n",
        "        \n",
        "        # Get staging annotations (if using Synapse workflow)\n",
        "        new_annot = {}\n",
        "        if staging_syn_id and staging_syn_id in staging_annotations:\n",
        "            staging_file_data = staging_annotations[staging_syn_id]\n",
        "            new_annot = list(staging_file_data.values())[0]\n",
        "        \n",
        "        # Merge: release > staging > template\n",
        "        merged_annot = merge_file_annotations(old_annot, new_annot, template)\n",
        "        \n",
        "        # Use release syn_id as key (we're updating existing entity)\n",
        "        annotations_dict[release_syn_id] = {form_name: merged_annot}\n",
        "\n",
        "    # Process new files (template only, but keep any staging annotations)\n",
        "    for staging_syn_id, filename, form_name in new_only:\n",
        "        if staging_syn_id:\n",
        "            # File exists in staging - use its annotations + template\n",
        "            if staging_syn_id in staging_annotations:\n",
        "                staging_file_data = staging_annotations[staging_syn_id]\n",
        "                staging_annot = list(staging_file_data.values())[0]\n",
        "                merged_annot = merge_annotations_into_template(template, staging_annot)\n",
        "            else:\n",
        "                merged_annot = template.copy()\n",
        "            \n",
        "            annotations_dict[staging_syn_id] = {form_name: merged_annot}\n",
        "        else:\n",
        "            # Local file only - use placeholder ID + template\n",
        "            clean_name = extract_clean_filename(filename)\n",
        "            placeholder_id = f\"NEW_{clean_name}\"\n",
        "            annotations_dict[placeholder_id] = {form_name: template.copy()}\n",
        "\n",
        "    # Save to file\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(annotations_dict, f, indent=2)\n",
        "\n",
        "    print(f\"‚úì Generated {output_file}\")\n",
        "    print(f\"  - {len(matched)} matched files (with merged annotations)\")\n",
        "    print(f\"  - {len(new_only)} new files\")\n",
        "\n",
        "\n",
        "# Generate annotation files\n",
        "print(\"=\" * 60)\n",
        "print(\"GENERATING ANNOTATION TEMPLATES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nGenerating ASSESS file annotations...\")\n",
        "generate_annotation_files_with_merging(\n",
        "    assess_matched, assess_new_only,\n",
        "    assess_existing_annotations, assess_staging_files,\n",
        "    ASSESS_ANNOTATIONS_FILE, 'ASSESS'\n",
        ")\n",
        "\n",
        "print(\"\\nGenerating PREVENT file annotations...\")\n",
        "generate_annotation_files_with_merging(\n",
        "    prevent_matched, prevent_new_only,\n",
        "    prevent_existing_annotations, prevent_staging_files,\n",
        "    PREVENT_ANNOTATIONS_FILE, 'PREVENT'\n",
        ")\n",
        "\n",
        "print(\"\\nGenerating dataset annotation templates...\")\n",
        "\n",
        "# Generate ASSESS dataset annotations (merge with existing)\n",
        "assess_dataset_template = create_dataset_annotation_template('ClinicalDataset')\n",
        "assess_dataset_merged = merge_annotations_into_template(assess_dataset_template, assess_dataset_existing_annotations)\n",
        "with open(ASSESS_DATASET_ANNOTATIONS_FILE, 'w') as f:\n",
        "    json.dump(assess_dataset_merged, f, indent=2)\n",
        "print(f\"‚úì Generated {ASSESS_DATASET_ANNOTATIONS_FILE}\")\n",
        "print(f\"  - Merged {len(assess_dataset_existing_annotations)} existing fields into template\")\n",
        "\n",
        "# Generate PREVENT dataset annotations (merge with existing)\n",
        "prevent_dataset_template = create_dataset_annotation_template('ClinicalDataset')\n",
        "prevent_dataset_merged = merge_annotations_into_template(prevent_dataset_template, prevent_dataset_existing_annotations)\n",
        "with open(PREVENT_DATASET_ANNOTATIONS_FILE, 'w') as f:\n",
        "    json.dump(prevent_dataset_merged, f, indent=2)\n",
        "print(f\"‚úì Generated {PREVENT_DATASET_ANNOTATIONS_FILE}\")\n",
        "print(f\"  - Merged {len(prevent_dataset_existing_annotations)} existing fields into template\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ANNOTATION FILES CREATED\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Files created in: {ANNOTATIONS_DIR}\")\n",
        "print(\"  - assess_file_annotations.json\")\n",
        "print(\"  - prevent_file_annotations.json\")\n",
        "print(\"  - assess_dataset_annotations.json\")\n",
        "print(\"  - prevent_dataset_annotations.json\")\n",
        "print(\"\\nAnnotation merging strategy:\")\n",
        "if USE_SYNAPSE_STAGING:\n",
        "    print(\"  Priority: Release > Staging > Template\")\n",
        "else:\n",
        "    print(\"  Priority: Release > Template (local file workflow)\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Manual Annotation Editing\n",
        "\n",
        "‚è∏Ô∏è **PAUSE HERE - Manual Editing Required**\n",
        "\n",
        "Before proceeding to the next cell:\n",
        "\n",
        "1. Navigate to: `/home/ramayyala/Documents/data-model/annotations/all_als/`\n",
        "2. Edit all 4 annotation JSON files with proper metadata:\n",
        "   - `assess_file_annotations.json`\n",
        "   - `prevent_file_annotations.json`\n",
        "   - `assess_dataset_annotations.json`\n",
        "   - `prevent_dataset_annotations.json`\n",
        "\n",
        "3. **Required fields** (must be filled):\n",
        "   - `title` (string)\n",
        "   - `creator` (list of strings)\n",
        "   - `keywords` (list of strings)\n",
        "   - `source` (string)\n",
        "   - `url` (string)\n",
        "\n",
        "4. **Optional but recommended**:\n",
        "   - `description`, `dataType`, `species`, `disease`, etc.\n",
        "\n",
        "5. For files with placeholder IDs (starting with \"NEW_\"):\n",
        "   - Either create the entity in Synapse first and replace with real syn_id\n",
        "   - Or skip these files in the upload step\n",
        "\n",
        "**Once editing is complete, save all files and proceed to the next cell for validation.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Load and Validate Annotations\n",
        "\n",
        "Load the edited annotation files and validate them against the data model schemas.\n",
        "\n",
        "**Validation must pass before proceeding to upload.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "LOADING AND VALIDATING ANNOTATIONS\n",
            "============================================================\n",
            "\n",
            "Loading annotation files...\n",
            "‚úì Loaded ASSESS file annotations: 30 files\n",
            "‚úì Loaded PREVENT file annotations: 48 files\n",
            "\n",
            "Validating ASSESS annotations...\n",
            "‚úì Loaded 54 schema definitions\n",
            "\n",
            "Validating PREVENT annotations...\n",
            "‚úì Loaded 54 schema definitions\n",
            "\n",
            "============================================================\n",
            "VALIDATION RESULTS\n",
            "============================================================\n",
            "\n",
            "ASSESS:\n",
            "  ‚úì All annotations valid (30 files)\n",
            "\n",
            "  ‚ö†Ô∏è  Warnings (3 files):\n",
            "    - syn68905760/ALSFRS-R:\n",
            "      ‚Ä¢ Field administrationMode is a list but should be a single value\n",
            "    - syn68905758/ALSFRS-R and Speech Anchor Questions:\n",
            "      ‚Ä¢ Field administrationMode is a list but should be a single value\n",
            "    - ASSESS Dataset:\n",
            "      ‚Ä¢ Field title is a list but should be a single value\n",
            "      ‚Ä¢ Field source is a list but should be a single value\n",
            "      ‚Ä¢ Field disease is a list but should be a single value\n",
            "      ‚Ä¢ Field studyType is a list but should be a single value\n",
            "      ‚Ä¢ Field individualCount is a list but should be a single value\n",
            "\n",
            "PREVENT:\n",
            "  ‚úì All annotations valid (48 files)\n",
            "\n",
            "  ‚ö†Ô∏è  Warnings (1 files):\n",
            "    - PREVENT Dataset:\n",
            "      ‚Ä¢ Field title is a list but should be a single value\n",
            "      ‚Ä¢ Field source is a list but should be a single value\n",
            "      ‚Ä¢ Field disease is a list but should be a single value\n",
            "      ‚Ä¢ Field studyType is a list but should be a single value\n",
            "      ‚Ä¢ Field individualCount is a list but should be a single value\n",
            "\n",
            "============================================================\n",
            "‚úÖ VALIDATION PASSED - Ready to proceed to file renaming\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "def load_annotation_file(file_path):\n",
        "    \"\"\"Load annotation JSON file.\"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"‚ö†Ô∏è  Warning: {file_path} not found\")\n",
        "        return {}\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "def validate_all_annotations(file_annotations, dataset_annotations, dataset_name):\n",
        "    \"\"\"\n",
        "    Validate all annotations for a dataset.\n",
        "    Returns: (is_valid, all_errors, warnings, valid_count)\n",
        "    \"\"\"\n",
        "    all_schemas = get_all_schemas()\n",
        "    errors_by_file = {}\n",
        "    warnings_by_file = {}\n",
        "    valid_count = 0\n",
        "\n",
        "    # Validate file annotations\n",
        "    for syn_id, file_data in file_annotations.items():\n",
        "        for filename, annotations in file_data.items():\n",
        "            file_type = annotations.get('_file_type', 'ClinicalFile')\n",
        "\n",
        "            is_valid, errors, warnings = validate_annotation_against_schema(\n",
        "                annotations, file_type, all_schemas\n",
        "            )\n",
        "\n",
        "            if errors:\n",
        "                errors_by_file[f\"{syn_id}/{filename}\"] = errors\n",
        "            if warnings:\n",
        "                warnings_by_file[f\"{syn_id}/{filename}\"] = warnings\n",
        "\n",
        "            if is_valid:\n",
        "                valid_count += 1\n",
        "\n",
        "    # Validate dataset annotations\n",
        "    dataset_type = dataset_annotations.get('_dataset_type', 'ClinicalDataset')\n",
        "    is_valid, errors, warnings = validate_annotation_against_schema(\n",
        "        dataset_annotations, dataset_type, all_schemas\n",
        "    )\n",
        "\n",
        "    if errors:\n",
        "        errors_by_file[f\"{dataset_name} Dataset\"] = errors\n",
        "    if warnings:\n",
        "        warnings_by_file[f\"{dataset_name} Dataset\"] = warnings\n",
        "\n",
        "    return (len(errors_by_file) == 0, errors_by_file, warnings_by_file, valid_count)\n",
        "\n",
        "\n",
        "# Load annotations\n",
        "print(\"=\" * 60)\n",
        "print(\"LOADING AND VALIDATING ANNOTATIONS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nLoading annotation files...\")\n",
        "assess_file_annotations = load_annotation_file(ASSESS_ANNOTATIONS_FILE)\n",
        "assess_dataset_annotations = load_annotation_file(ASSESS_DATASET_ANNOTATIONS_FILE)\n",
        "prevent_file_annotations = load_annotation_file(PREVENT_ANNOTATIONS_FILE)\n",
        "prevent_dataset_annotations = load_annotation_file(PREVENT_DATASET_ANNOTATIONS_FILE)\n",
        "\n",
        "print(f\"‚úì Loaded ASSESS file annotations: {len(assess_file_annotations)} files\")\n",
        "print(f\"‚úì Loaded PREVENT file annotations: {len(prevent_file_annotations)} files\")\n",
        "\n",
        "# Validate annotations\n",
        "print(\"\\nValidating ASSESS annotations...\")\n",
        "assess_valid, assess_errors, assess_warnings, assess_valid_count = validate_all_annotations(\n",
        "    assess_file_annotations, assess_dataset_annotations, 'ASSESS'\n",
        ")\n",
        "\n",
        "print(f\"\\nValidating PREVENT annotations...\")\n",
        "prevent_valid, prevent_errors, prevent_warnings, prevent_valid_count = validate_all_annotations(\n",
        "    prevent_file_annotations, prevent_dataset_annotations, 'PREVENT'\n",
        ")\n",
        "\n",
        "# Report results\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"VALIDATION RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nASSESS:\")\n",
        "if assess_valid:\n",
        "    print(f\"  ‚úì All annotations valid ({assess_valid_count} files)\")\n",
        "else:\n",
        "    print(f\"  ‚úó Validation failed ({len(assess_errors)} files with errors)\")\n",
        "    print(\"\\n  Errors:\")\n",
        "    for file_id, errors in assess_errors.items():\n",
        "        print(f\"    - {file_id}:\")\n",
        "        for error in errors:\n",
        "            print(f\"      ‚Ä¢ {error}\")\n",
        "\n",
        "if assess_warnings:\n",
        "    print(f\"\\n  ‚ö†Ô∏è  Warnings ({len(assess_warnings)} files):\")\n",
        "    for file_id, warnings in assess_warnings.items():\n",
        "        print(f\"    - {file_id}:\")\n",
        "        for warning in warnings:\n",
        "            print(f\"      ‚Ä¢ {warning}\")\n",
        "\n",
        "print(f\"\\nPREVENT:\")\n",
        "if prevent_valid:\n",
        "    print(f\"  ‚úì All annotations valid ({prevent_valid_count} files)\")\n",
        "else:\n",
        "    print(f\"  ‚úó Validation failed ({len(prevent_errors)} files with errors)\")\n",
        "    print(\"\\n  Errors:\")\n",
        "    for file_id, errors in prevent_errors.items():\n",
        "        print(f\"    - {file_id}:\")\n",
        "        for error in errors:\n",
        "            print(f\"      ‚Ä¢ {error}\")\n",
        "\n",
        "if prevent_warnings:\n",
        "    print(f\"\\n  ‚ö†Ô∏è  Warnings ({len(prevent_warnings)} files):\")\n",
        "    for file_id, warnings in prevent_warnings.items():\n",
        "        print(f\"    - {file_id}:\")\n",
        "        for warning in warnings:\n",
        "            print(f\"      ‚Ä¢ {warning}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "if not (assess_valid and prevent_valid):\n",
        "    print(\"‚ùå VALIDATION FAILED - Please fix errors before proceeding\")\n",
        "    print(\"   Edit the annotation files and re-run this cell\")\n",
        "else:\n",
        "    print(\"‚úÖ VALIDATION PASSED - Ready to proceed to file renaming\")\n",
        "\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Rename Files Using Form Name Mappings\n",
        "\n",
        "Create staging directory with renamed files for upload:\n",
        "- `v_ALLALS_AS_ASSEDEMOG.csv` ‚Üí `Demographics.csv`\n",
        "\n",
        "Files are copied (not moved) to staging directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DOWNLOADING AND RENAMING FILES\n",
            "============================================================\n",
            "\n",
            "Downloading ASSESS files from staging folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46.2k/46.2k [00:00<00:00, 198kB/s, syn71824511]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824511]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEAELOG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46.2k/46.2k [00:00<00:00, 197kB/s, syn71824511]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEAELOG.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEAELOG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 164k/164k [00:00<00:00, 902kB/s, syn71824519]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824519]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEALSFRSR.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 164k/164k [00:00<00:00, 893kB/s, syn71824519]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEALSFRSR.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEALSFRSR.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105k/105k [00:00<00:00, 415kB/s, syn71824508]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824508]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEALSFRSRSAQ.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105k/105k [00:00<00:00, 412kB/s, syn71824508]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEALSFRSRSAQ.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEALSFRSRSAQ.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65.3k/65.3k [00:00<00:00, 389kB/s, syn71824509]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824509]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEALSHIST.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65.3k/65.3k [00:00<00:00, 384kB/s, syn71824509]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEALSHIST.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEALSHIST.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101k/101k [00:00<00:00, 330kB/s, syn71824507]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824507]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEBLDCOL.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101k/101k [00:00<00:00, 327kB/s, syn71824507]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEBLDCOL.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEBLDCOL.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 581k/581k [00:00<00:00, 2.06MB/s, syn71824513]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824513]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSECONMD.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 581k/581k [00:00<00:00, 2.05MB/s, syn71824513]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSECONMD.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSECONMD.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.9k/15.9k [00:00<00:00, 154kB/s, syn71824510]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824510]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSECSFCO.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.9k/15.9k [00:00<00:00, 151kB/s, syn71824510]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSECSFCO.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSECSFCO.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55.8k/55.8k [00:00<00:00, 374kB/s, syn71824512]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824512]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEDEMOG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55.8k/55.8k [00:00<00:00, 369kB/s, syn71824512]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEDEMOG.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEDEMOG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50.6k/50.6k [00:00<00:00, 489kB/s, syn71824514]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824514]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEDSA.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50.6k/50.6k [00:00<00:00, 474kB/s, syn71824514]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEDSA.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEDSA.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63.5k/63.5k [00:00<00:00, 284kB/s, syn71824516]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824516]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEDSAUI.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63.5k/63.5k [00:00<00:00, 281kB/s, syn71824516]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEDSAUI.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEDSAUI.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 142k/142k [00:00<00:00, 723kB/s, syn71824524]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824524]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEECAS.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 142k/142k [00:00<00:00, 716kB/s, syn71824524]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEECAS.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEECAS.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 184k/184k [00:00<00:00, 719kB/s, syn71824517]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824517]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEECASCGI.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 184k/184k [00:00<00:00, 714kB/s, syn71824517]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEECASCGI.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEECASCGI.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.9k/10.9k [00:00<00:00, 76.7kB/s, syn71824515]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824515]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEELCONLMP.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.9k/10.9k [00:00<00:00, 75.6kB/s, syn71824515]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEELCONLMP.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEELCONLMP.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55.1k/55.1k [00:00<00:00, 605kB/s, syn71824523]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824523]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEELCONREG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55.1k/55.1k [00:00<00:00, 592kB/s, syn71824523]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEELCONREG.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEELCONREG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.5k/11.5k [00:00<00:00, 85.7kB/s, syn71824518]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824518]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEELIGCRIREG2.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.5k/11.5k [00:00<00:00, 79.4kB/s, syn71824518]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEELIGCRIREG2.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEELIGCRIREG2.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23.3k/23.3k [00:00<00:00, 158kB/s, syn71824520]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824520]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEELIGCRISYM2.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23.3k/23.3k [00:00<00:00, 156kB/s, syn71824520]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEELIGCRISYM2.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEELIGCRISYM2.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16.1k/16.1k [00:00<00:00, 147kB/s, syn71824521]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824521]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEELIGCRITLMP.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16.1k/16.1k [00:00<00:00, 144kB/s, syn71824521]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEELIGCRITLMP.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEELIGCRITLMP.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.0k/17.0k [00:00<00:00, 88.9kB/s, syn71824522]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824522]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEELIGCRITREG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.0k/17.0k [00:00<00:00, 80.8kB/s, syn71824522]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEELIGCRITREG.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEELIGCRITREG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54.0k/54.0k [00:00<00:00, 431kB/s, syn71824525]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824525]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEELIGCRITSYM.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54.0k/54.0k [00:00<00:00, 423kB/s, syn71824525]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEELIGCRITSYM.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEELIGCRITSYM.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 260k/260k [00:00<00:00, 932kB/s, syn71824526]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824526]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEFAMHIST.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 260k/260k [00:00<00:00, 923kB/s, syn71824526]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEFAMHIST.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEFAMHIST.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200k/200k [00:00<00:00, 844kB/s, syn71824527] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824527]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEHHD.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200k/200k [00:00<00:00, 729kB/s, syn71824527]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEHHD.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEHHD.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83.8k/83.8k [00:00<00:00, 291kB/s, syn71824529]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824529]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEICF.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83.8k/83.8k [00:00<00:00, 289kB/s, syn71824529]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEICF.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEICF.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91.5k/91.5k [00:00<00:00, 518kB/s, syn71824530]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824530]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEKEYDEV.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91.5k/91.5k [00:00<00:00, 513kB/s, syn71824530]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEKEYDEV.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEKEYDEV.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 390k/390k [00:00<00:00, 1.45MB/s, syn71824535]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824535]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEMEDHX.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 390k/390k [00:00<00:00, 1.44MB/s, syn71824535]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEMEDHX.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEMEDHX.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13.1k/13.1k [00:00<00:00, 108kB/s, syn71824531]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824531]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEPARTFINDI.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13.1k/13.1k [00:00<00:00, 106kB/s, syn71824531]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEPARTFINDI.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEPARTFINDI.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 161k/161k [00:00<00:00, 514kB/s, syn71824532]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824532]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEPDEVAD.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 161k/161k [00:00<00:00, 510kB/s, syn71824532]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEPDEVAD.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEPDEVAD.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69.3k/69.3k [00:00<00:00, 288kB/s, syn71824533]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824533]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEPRALSGENTST.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69.3k/69.3k [00:00<00:00, 285kB/s, syn71824533]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEPRALSGENTST.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEPRALSGENTST.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107k/107k [00:00<00:00, 524kB/s, syn71824534]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824534]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEVC.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107k/107k [00:00<00:00, 520kB/s, syn71824534]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEVC.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEVC.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 122k/122k [00:00<00:00, 720kB/s, syn71824539]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824539]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEVISTYPE.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 122k/122k [00:00<00:00, 713kB/s, syn71824539]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEVISTYPE.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEVISTYPE.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 94.0k/94.0k [00:00<00:00, 516kB/s, syn71824538]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824538]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEVITSIGN.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 94.0k/94.0k [00:00<00:00, 509kB/s, syn71824538]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_AS_ASSEVITSIGN.csv to /home/ramayyala/Documents/data-model/downloads/all_als/assess/v_ALLALS_AS_ASSEVITSIGN.csv\n",
            "\n",
            "  Downloaded: 30, Local: 0, Errors: 0\n",
            "\n",
            "Renaming ASSESS files...\n",
            "  ‚úì v_ALLALS_AS_ASSEAELOG.csv ‚Üí Adverse Event (AE) Log.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEALSFRSR.csv ‚Üí ALSFRSR.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEALSFRSRSAQ.csv ‚Üí ALSFRSR and Speech Anchor Questions.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEALSHIST.csv ‚Üí ALS History.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEBLDCOL.csv ‚Üí Blood Collection (ASSESS).csv\n",
            "  ‚úì v_ALLALS_AS_ASSECONMD.csv ‚Üí Concomitant Medication Log.csv\n",
            "  ‚úì v_ALLALS_AS_ASSECSFCO.csv ‚Üí Cerebral Spinal Fluid (CSF) Collection.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEDEMOG.csv ‚Üí Demographics.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEDSA.csv ‚Üí Digital Speech Assessment.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEDSAUI.csv ‚Üí Digital Speech Assessment User Information.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEECAS.csv ‚Üí ECAS (Edinburgh Cognitive and Behavioral ALS Screen).csv\n",
            "  ‚úì v_ALLALS_AS_ASSEECASCGI.csv ‚Üí ECAS (Edinburgh Cognitive and Behavioral ALS Screen) Caregiver Interview.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEELCONLMP.csv ‚Üí Lumbar Puncture Eligibility Confirmation.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEELCONREG.csv ‚Üí Enrollment Confirmation.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEELIGCRITREG.csv ‚Üí Eligibility Criteria (ASSESS Control).csv\n",
            "  ‚úì v_ALLALS_AS_ASSEELIGCRITSYM.csv ‚Üí Eligibility Criteria (ASSESS Symptomatic).csv\n",
            "  ‚úì v_ALLALS_AS_ASSEELIGCRITLMP.csv ‚Üí Lumbar Puncture Eligibility Criteria.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEFAMHIST.csv ‚Üí Family History.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEHHD.csv ‚Üí Modified HandHeld Dynamometry (HHD).csv\n",
            "  ‚úì v_ALLALS_AS_ASSEICF.csv ‚Üí Informed Consent Log.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEKEYDEV.csv ‚Üí Key Devices and Procedures Log.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEMEDHX.csv ‚Üí Medical History.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEPARTFINDI.csv ‚Üí ASSESS Participant Final Disposition.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEPDEVAD.csv ‚Üí Protocol Deviation Log.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEPRALSGENTST.csv ‚Üí Prior ALS Genetic Testing.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEVC.csv ‚Üí Vital Capacity (VC).csv\n",
            "  ‚úì v_ALLALS_AS_ASSEVISTYPE.csv ‚Üí Visit Type.csv\n",
            "  ‚úì v_ALLALS_AS_ASSEVITSIGN.csv ‚Üí Vital Signs (ASSESS).csv\n",
            "\n",
            "  Total: 28 files renamed, 0 errors\n",
            "\n",
            "Downloading PREVENT files from staging folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.1k/15.1k [00:00<00:00, 127kB/s, syn71824457]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824457]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVAELOG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.1k/15.1k [00:00<00:00, 125kB/s, syn71824457]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVAELOG.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVAELOG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42.5k/42.5k [00:00<00:00, 180kB/s, syn71824459]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824459]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVBLDCOLINC.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42.5k/42.5k [00:00<00:00, 178kB/s, syn71824459]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVBLDCOLINC.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVBLDCOLINC.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22.5k/22.5k [00:00<00:00, 217kB/s, syn71824462]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824462]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVBLDCOLREM.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22.5k/22.5k [00:00<00:00, 212kB/s, syn71824462]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVBLDCOLREM.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVBLDCOLREM.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167k/167k [00:00<00:00, 1.33MB/s, syn71824464]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824464]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVCONMD.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167k/167k [00:00<00:00, 1.30MB/s, syn71824464]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVCONMD.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVCONMD.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.5k/18.5k [00:00<00:00, 110kB/s, syn71824461]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824461]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVCSFCO.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.5k/18.5k [00:00<00:00, 98.3kB/s, syn71824461]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVCSFCO.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVCSFCO.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.0k/18.0k [00:00<00:00, 161kB/s, syn71824460]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824460]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVDEMOG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.0k/18.0k [00:00<00:00, 155kB/s, syn71824460]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVDEMOG.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVDEMOG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37.8k/37.8k [00:00<00:00, 350kB/s, syn71824463]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824463]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVDSA.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37.8k/37.8k [00:00<00:00, 341kB/s, syn71824463]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVDSA.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVDSA.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31.6k/31.6k [00:00<00:00, 298kB/s, syn71824476]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824476]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVDSAUI.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31.6k/31.6k [00:00<00:00, 293kB/s, syn71824476]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVDSAUI.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVDSAUI.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74.6k/74.6k [00:00<00:00, 348kB/s, syn71824468]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824468]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVECAS.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74.6k/74.6k [00:00<00:00, 344kB/s, syn71824468]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVECAS.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVECAS.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89.6k/89.6k [00:00<00:00, 388kB/s, syn71824466]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824466]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVECASCGI.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89.6k/89.6k [00:00<00:00, 384kB/s, syn71824466]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVECASCGI.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVECASCGI.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.8k/12.8k [00:00<00:00, 139kB/s, syn71824465]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824465]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELCONGEN.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.8k/12.8k [00:00<00:00, 136kB/s, syn71824465]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVELCONGEN.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELCONGEN.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.7k/17.7k [00:00<00:00, 67.2kB/s, syn71824471]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824471]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELCONLMP.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.7k/17.7k [00:00<00:00, 66.7kB/s, syn71824471]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVELCONLMP.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELCONLMP.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25.8k/25.8k [00:00<00:00, 185kB/s, syn71824467]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824467]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELCONREG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25.8k/25.8k [00:00<00:00, 167kB/s, syn71824467]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVELCONREG.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELCONREG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.5k/15.5k [00:00<00:00, 132kB/s, syn71824469]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824469]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELIGCRITA2.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.5k/15.5k [00:00<00:00, 130kB/s, syn71824469]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVELIGCRITA2.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELIGCRITA2.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.0k/11.0k [00:00<00:00, 77.7kB/s, syn71824470]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824470]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELIGCRITGEN.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.0k/11.0k [00:00<00:00, 76.5kB/s, syn71824470]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVELIGCRITGEN.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELIGCRITGEN.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26.7k/26.7k [00:00<00:00, 208kB/s, syn71824472]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824472]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELIGCRITLMP.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26.7k/26.7k [00:00<00:00, 186kB/s, syn71824472]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVELIGCRITLMP.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELIGCRITLMP.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34.0k/34.0k [00:00<00:00, 263kB/s, syn71824474]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824474]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELIGCRITREG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34.0k/34.0k [00:00<00:00, 257kB/s, syn71824474]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVELIGCRITREG.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELIGCRITREG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.00k/5.00k [00:00<00:00, 23.2kB/s, syn71824473]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824473]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELIGCRTGEN2.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.00k/5.00k [00:00<00:00, 23.0kB/s, syn71824473]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVELIGCRTGEN2.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVELIGCRTGEN2.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.9k/17.9k [00:00<00:00, 91.5kB/s, syn71824475]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824475]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVEMG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.9k/17.9k [00:00<00:00, 90.6kB/s, syn71824475]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVEMG.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVEMG.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43.9k/43.9k [00:00<00:00, 403kB/s, syn71824477]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824477]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVENDVISFRM.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43.9k/43.9k [00:00<00:00, 380kB/s, syn71824477]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVENDVISFRM.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVENDVISFRM.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274k/274k [00:00<00:00, 1.18MB/s, syn71824479]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824479]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVFAMHIST.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274k/274k [00:00<00:00, 1.16MB/s, syn71824479]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVFAMHIST.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVFAMHIST.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37.2k/37.2k [00:00<00:00, 314kB/s, syn71824480]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824480]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVGENCOUNREF.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37.2k/37.2k [00:00<00:00, 309kB/s, syn71824480]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVGENCOUNREF.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVGENCOUNREF.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36.6k/36.6k [00:00<00:00, 317kB/s, syn71824481]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824481]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVGENCRPL.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36.6k/36.6k [00:00<00:00, 311kB/s, syn71824481]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVGENCRPL.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVGENCRPL.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.13k/7.13k [00:00<00:00, 75.1kB/s, syn71824482]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824482]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVGENTSTRES.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.13k/7.13k [00:00<00:00, 73.8kB/s, syn71824482]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVGENTSTRES.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVGENTSTRES.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45.4k/45.4k [00:00<00:00, 482kB/s, syn71824492]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824492]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVGST.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45.4k/45.4k [00:00<00:00, 469kB/s, syn71824492]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVGST.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVGST.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42.7k/42.7k [00:00<00:00, 375kB/s, syn71824483]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824483]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVICF.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42.7k/42.7k [00:00<00:00, 366kB/s, syn71824483]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVICF.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVICF.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25.7k/25.7k [00:00<00:00, 275kB/s, syn71824486]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824486]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVKEYDEV.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25.7k/25.7k [00:00<00:00, 271kB/s, syn71824486]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVKEYDEV.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVKEYDEV.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 194k/194k [00:00<00:00, 914kB/s, syn71824491]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824491]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVMEDHX.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 194k/194k [00:00<00:00, 906kB/s, syn71824491]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVMEDHX.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVMEDHX.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.8k/17.8k [00:00<00:00, 84.7kB/s, syn71824487]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824487]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVMIRPARTI.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.8k/17.8k [00:00<00:00, 84.0kB/s, syn71824487]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVMIRPARTI.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVMIRPARTI.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65.9k/65.9k [00:00<00:00, 477kB/s, syn71824488]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824488]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVMIRSCRPR.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65.9k/65.9k [00:00<00:00, 470kB/s, syn71824488]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVMIRSCRPR.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVMIRSCRPR.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.7k/18.7k [00:00<00:00, 182kB/s, syn71824489]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824489]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVMIRSCRSP.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.7k/18.7k [00:00<00:00, 177kB/s, syn71824489]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVMIRSCRSP.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVMIRSCRSP.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.0k/18.0k [00:00<00:00, 86.3kB/s, syn71824490]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824490]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVMIRSTYP.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.0k/18.0k [00:00<00:00, 85.6kB/s, syn71824490]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVMIRSTYP.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVMIRSTYP.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 385k/385k [00:00<00:00, 1.50MB/s, syn71824501]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824501]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVNUROEX.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 385k/385k [00:00<00:00, 1.49MB/s, syn71824501]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVNUROEX.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVNUROEX.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.09k/4.09k [00:00<00:00, 36.9kB/s, syn71824494]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824494]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVPARTFINDIS.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.09k/4.09k [00:00<00:00, 36.2kB/s, syn71824494]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVPARTFINDIS.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVPARTFINDIS.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112k/112k [00:00<00:00, 641kB/s, syn71824495]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824495]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVPDEVAD.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112k/112k [00:00<00:00, 634kB/s, syn71824495]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVPDEVAD.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVPDEVAD.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.96k/6.96k [00:00<00:00, 123kB/s, syn71824497]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824497]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVPHENOCONVER.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.96k/6.96k [00:00<00:00, 119kB/s, syn71824497]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVPHENOCONVER.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVPHENOCONVER.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.72k/1.72k [00:00<00:00, 16.2kB/s, syn71824496]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824496]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVPHEXM.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.72k/1.72k [00:00<00:00, 15.9kB/s, syn71824496]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVPHEXM.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVPHEXM.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.2k/44.2k [00:00<00:00, 198kB/s, syn71824498]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824498]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVPRALSGENTST.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.2k/44.2k [00:00<00:00, 197kB/s, syn71824498]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVPRALSGENTST.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVPRALSGENTST.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22.9k/22.9k [00:00<00:00, 198kB/s, syn71824502]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824502]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVSYMPQUES.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22.9k/22.9k [00:00<00:00, 195kB/s, syn71824502]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVSYMPQUES.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVSYMPQUES.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55.2k/55.2k [00:00<00:00, 285kB/s, syn71824503]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824503]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVVC.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55.2k/55.2k [00:00<00:00, 257kB/s, syn71824503]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVVC.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVVC.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67.6k/67.6k [00:00<00:00, 575kB/s, syn71824504]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824504]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVVISTYPE.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67.6k/67.6k [00:00<00:00, 565kB/s, syn71824504]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVVISTYPE.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVVISTYPE.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.6k/12.6k [00:00<00:00, 113kB/s, syn71824505]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[syn71824505]: Downloaded to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVWEIGHT.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.6k/12.6k [00:00<00:00, 111kB/s, syn71824505]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Downloaded v_ALLALS_PR_PREVWEIGHT.csv to /home/ramayyala/Documents/data-model/downloads/all_als/prevent/v_ALLALS_PR_PREVWEIGHT.csv\n",
            "\n",
            "  Downloaded: 42, Local: 0, Errors: 0\n",
            "\n",
            "Renaming PREVENT files...\n",
            "  ‚úì v_ALLALS_PR_PREVAELOG.csv ‚Üí Adverse Event (AE) Log.csv\n",
            "  ‚úì v_ALLALS_PR_PREVBLDCOLINC.csv ‚Üí Blood Collection (PREVENT InClinic).csv\n",
            "  ‚úì v_ALLALS_PR_PREVBLDCOLREM.csv ‚Üí Blood Collection (PREVENT Remote).csv\n",
            "  ‚úì v_ALLALS_PR_PREVCONMD.csv ‚Üí Concomitant Medication Log.csv\n",
            "  ‚úì v_ALLALS_PR_PREVCSFCO.csv ‚Üí Cerebral Spinal Fluid (CSF) Collection.csv\n",
            "  ‚úì v_ALLALS_PR_PREVDEMOG.csv ‚Üí Demographics.csv\n",
            "  ‚úì v_ALLALS_PR_PREVDSA.csv ‚Üí Digital Speech Assessment.csv\n",
            "  ‚úì v_ALLALS_PR_PREVDSAUI.csv ‚Üí Digital Speech Assessment User Information.csv\n",
            "  ‚úì v_ALLALS_PR_PREVECAS.csv ‚Üí ECAS (Edinburgh Cognitive and Behavioral ALS Screen).csv\n",
            "  ‚úì v_ALLALS_PR_PREVECASCGI.csv ‚Üí ECAS (Edinburgh Cognitive and Behavioral ALS Screen) Caregiver Interview.csv\n",
            "  ‚úì v_ALLALS_PR_PREVELCONGEN.csv ‚Üí Enrollment Confirmation (PREVENT Genetic Testing SubStudy).csv\n",
            "  ‚úì v_ALLALS_PR_PREVELCONLMP.csv ‚Üí Lumbar Puncture Eligibility Confirmation.csv\n",
            "  ‚úì v_ALLALS_PR_PREVELCONREG.csv ‚Üí Enrollment Confirmation.csv\n",
            "  ‚úì v_ALLALS_PR_PREVELIGCRITREG.csv ‚Üí Eligibility Criteria (PREVENT).csv\n",
            "  ‚úì v_ALLALS_PR_PREVELIGCRTGEN2.csv ‚Üí Eligibility Criteria (PREVENT Genetic Testing SubStudy).csv\n",
            "  ‚úì v_ALLALS_PR_PREVELIGCRITLMP.csv ‚Üí Lumbar Puncture Eligibility Criteria.csv\n",
            "  ‚úì v_ALLALS_PR_PREVEMG.csv ‚Üí EMG.csv\n",
            "  ‚úì v_ALLALS_PR_PREVENDVISFRM.csv ‚Üí PREVENT End of Visit Form.csv\n",
            "  ‚úì v_ALLALS_PR_PREVFAMHIST.csv ‚Üí Family History.csv\n",
            "  ‚úì v_ALLALS_PR_PREVGENCOUNREF.csv ‚Üí Genetic Counseling Referral.csv\n",
            "  ‚úì v_ALLALS_PR_PREVGENCRPL.csv ‚Üí ALS Gene Carrier Research Participation Log.csv\n",
            "  ‚úì v_ALLALS_PR_PREVGENTSTRES.csv ‚Üí PREVENT Genetic Testing Results.csv\n",
            "  ‚úì v_ALLALS_PR_PREVGST.csv ‚Üí Grip Strength Testing.csv\n",
            "  ‚úì v_ALLALS_PR_PREVICF.csv ‚Üí Informed Consent Log.csv\n",
            "  ‚úì v_ALLALS_PR_PREVKEYDEV.csv ‚Üí Key Devices and Procedures Log.csv\n",
            "  ‚úì v_ALLALS_PR_PREVMEDHX.csv ‚Üí Medical History.csv\n",
            "  ‚úì v_ALLALS_PR_PREVMIRPARTI.csv ‚Üí MIR (Participant).csv\n",
            "  ‚úì v_ALLALS_PR_PREVMIRSCRPR.csv ‚Üí MIR Screener (Participant).csv\n",
            "  ‚úì v_ALLALS_PR_PREVMIRSCRSP.csv ‚Üí MIR Screener (Study Partner).csv\n",
            "  ‚úì v_ALLALS_PR_PREVMIRSTYP.csv ‚Üí MIR (Study Partner).csv\n",
            "  ‚úì v_ALLALS_PR_PREVNUROEX.csv ‚Üí Neurological Examination.csv\n",
            "  ‚úì v_ALLALS_PR_PREVPARTFINDIS.csv ‚Üí PREVENT Participant Final Disposition.csv\n",
            "  ‚úì v_ALLALS_PR_PREVPDEVAD.csv ‚Üí Protocol Deviation Log.csv\n",
            "  ‚úì v_ALLALS_PR_PREVPHENOCONVER.csv ‚Üí Phenoconversion.csv\n",
            "  ‚úì v_ALLALS_PR_PREVPHEXM.csv ‚Üí Physical Examination.csv\n",
            "  ‚úì v_ALLALS_PR_PREVPRALSGENTST.csv ‚Üí Prior ALS Genetic Testing.csv\n",
            "  ‚úì v_ALLALS_PR_PREVSYMPQUES.csv ‚Üí PREVENT Symptom Questionnaire.csv\n",
            "  ‚úì v_ALLALS_PR_PREVVC.csv ‚Üí Vital Capacity (VC).csv\n",
            "  ‚úì v_ALLALS_PR_PREVVISTYPE.csv ‚Üí Visit Type.csv\n",
            "  ‚úì v_ALLALS_PR_PREVWEIGHT.csv ‚Üí Weight.csv\n",
            "\n",
            "  Total: 40 files renamed, 0 errors\n",
            "\n",
            "============================================================\n",
            "FILE PREPARATION COMPLETE\n",
            "============================================================\n",
            "ASSESS staged files: 28\n",
            "  Location: /home/ramayyala/Documents/data-model/staging/all_als/assess\n",
            "\n",
            "PREVENT staged files: 40\n",
            "  Location: /home/ramayyala/Documents/data-model/staging/all_als/prevent\n",
            "\n",
            "Downloaded files location:\n",
            "  - ASSESS: /home/ramayyala/Documents/data-model/downloads/all_als/assess\n",
            "  - PREVENT: /home/ramayyala/Documents/data-model/downloads/all_als/prevent\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def download_matched_files(syn, matched, staging_dir, download_dir, dataset_name):\n",
        "    \"\"\"\n",
        "    Download new file versions from Synapse staging folder.\n",
        "    \n",
        "    Args:\n",
        "        syn: Synapse client\n",
        "        matched: List of (staging_syn_id, release_syn_id, local_path, form_name)\n",
        "        staging_dir: Directory for downloaded files\n",
        "        download_dir: Directory to download to\n",
        "        dataset_name: Name of dataset (for logging)\n",
        "    \n",
        "    Returns: Dict[form_name ‚Üí downloaded_path or local_path]\n",
        "    \"\"\"\n",
        "    file_paths = {}\n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "    local_count = 0\n",
        "    \n",
        "    for staging_syn_id, release_syn_id, local_path, form_name in matched:\n",
        "        if staging_syn_id:\n",
        "            # Download from Synapse staging folder\n",
        "            downloaded_path = download_synapse_file(syn, staging_syn_id, download_dir)\n",
        "            \n",
        "            if downloaded_path:\n",
        "                file_paths[form_name] = downloaded_path\n",
        "                success_count += 1\n",
        "            elif local_path:\n",
        "                # Fallback to local file\n",
        "                print(f\"  ‚ö†Ô∏è  Using local fallback for {form_name}\")\n",
        "                file_paths[form_name] = local_path\n",
        "                local_count += 1\n",
        "            else:\n",
        "                print(f\"  ‚úó No file available for {form_name}\")\n",
        "                error_count += 1\n",
        "        else:\n",
        "            # Use local file (local workflow)\n",
        "            if local_path:\n",
        "                file_paths[form_name] = local_path\n",
        "                local_count += 1\n",
        "            else:\n",
        "                print(f\"  ‚úó No local file for {form_name}\")\n",
        "                error_count += 1\n",
        "    \n",
        "    print(f\"\\n  Downloaded: {success_count}, Local: {local_count}, Errors: {error_count}\")\n",
        "    return file_paths\n",
        "\n",
        "\n",
        "def create_renamed_staging_directory(file_paths, staging_dir, dataset_name):\n",
        "    \"\"\"\n",
        "    Copy and rename files to staging directory.\n",
        "    \n",
        "    Args:\n",
        "        file_paths: Dict[form_name ‚Üí file_path]\n",
        "        staging_dir: Directory to copy renamed files to\n",
        "        dataset_name: Name of dataset (for logging)\n",
        "    \n",
        "    Returns: Dict[form_name ‚Üí (renamed_filename, staged_path)]\n",
        "    \"\"\"\n",
        "    rename_map = {}\n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "\n",
        "    # Clear staging directory\n",
        "    if os.path.exists(staging_dir):\n",
        "        shutil.rmtree(staging_dir)\n",
        "    os.makedirs(staging_dir, exist_ok=True)\n",
        "\n",
        "    for form_name, source_path in file_paths.items():\n",
        "        try:\n",
        "            # Determine renamed filename\n",
        "            # Sanitize form name to comply with Synapse naming rules\n",
        "            sanitized_form_name = sanitize_synapse_filename(form_name)\n",
        "            renamed_filename = f\"{sanitized_form_name}.csv\"\n",
        "            staged_path = os.path.join(staging_dir, renamed_filename)\n",
        "\n",
        "            # Copy file to staging\n",
        "            shutil.copy2(source_path, staged_path)\n",
        "\n",
        "            rename_map[form_name] = (renamed_filename, staged_path)\n",
        "            success_count += 1\n",
        "\n",
        "            if VERBOSE:\n",
        "                print(f\"  ‚úì {os.path.basename(source_path)} ‚Üí {renamed_filename}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚úó Error renaming {form_name}: {e}\")\n",
        "            error_count += 1\n",
        "\n",
        "    print(f\"\\n  Total: {success_count} files renamed, {error_count} errors\")\n",
        "    return rename_map\n",
        "\n",
        "\n",
        "# Download and rename files\n",
        "print(\"=\" * 60)\n",
        "print(\"DOWNLOADING AND RENAMING FILES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Connect to Synapse (needed for downloads even in DRY_RUN)\n",
        "if USE_SYNAPSE_STAGING:\n",
        "    if 'syn' not in globals() or syn is None:\n",
        "        syn = connect_to_synapse()\n",
        "else:\n",
        "    syn = None\n",
        "\n",
        "# Download ASSESS files (if using Synapse staging)\n",
        "if USE_SYNAPSE_STAGING:\n",
        "    print(\"\\nDownloading ASSESS files from staging folder...\")\n",
        "    assess_file_paths = download_matched_files(\n",
        "        syn, assess_matched, ASSESS_STAGING_DIR, ASSESS_DOWNLOAD_DIR, 'ASSESS'\n",
        "    )\n",
        "else:\n",
        "    print(\"\\nUsing local ASSESS files...\")\n",
        "    assess_file_paths = {}\n",
        "    for _, release_syn_id, local_path, form_name in assess_matched:\n",
        "        if local_path:\n",
        "            assess_file_paths[form_name] = local_path\n",
        "\n",
        "print(f\"\\nRenaming ASSESS files...\")\n",
        "assess_rename_map = create_renamed_staging_directory(\n",
        "    assess_file_paths, ASSESS_STAGING_DIR, 'ASSESS'\n",
        ")\n",
        "\n",
        "# Download PREVENT files (if using Synapse staging)\n",
        "if USE_SYNAPSE_STAGING:\n",
        "    print(\"\\nDownloading PREVENT files from staging folder...\")\n",
        "    prevent_file_paths = download_matched_files(\n",
        "        syn, prevent_matched, PREVENT_STAGING_DIR, PREVENT_DOWNLOAD_DIR, 'PREVENT'\n",
        "    )\n",
        "else:\n",
        "    print(\"\\nUsing local PREVENT files...\")\n",
        "    prevent_file_paths = {}\n",
        "    for _, release_syn_id, local_path, form_name in prevent_matched:\n",
        "        if local_path:\n",
        "            prevent_file_paths[form_name] = local_path\n",
        "\n",
        "print(f\"\\nRenaming PREVENT files...\")\n",
        "prevent_rename_map = create_renamed_staging_directory(\n",
        "    prevent_file_paths, PREVENT_STAGING_DIR, 'PREVENT'\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FILE PREPARATION COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"ASSESS staged files: {len(assess_rename_map)}\")\n",
        "print(f\"  Location: {ASSESS_STAGING_DIR}\")\n",
        "print(f\"\\nPREVENT staged files: {len(prevent_rename_map)}\")\n",
        "print(f\"  Location: {PREVENT_STAGING_DIR}\")\n",
        "if USE_SYNAPSE_STAGING:\n",
        "    print(f\"\\nDownloaded files location:\")\n",
        "    print(f\"  - ASSESS: {ASSESS_DOWNLOAD_DIR}\")\n",
        "    print(f\"  - PREVENT: {PREVENT_DOWNLOAD_DIR}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "UPLOADING FILES AND MOVING NEW FILES (DRY_RUN=False)\n",
            "============================================================\n",
            "\n",
            "--- ASSESS Dataset ---\n",
            "\n",
            "Uploading ASSESS matched files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46.2k/46.2k [00:00<00:00, 132kB/s, Adverse Event (AE) Log.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Adverse Event (AE) Log.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 164k/164k [00:00<00:00, 299kB/s, ALSFRSR.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded ALSFRSR.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105k/105k [00:00<00:00, 351kB/s, ALSFRSR and Speech Anchor Questions.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded ALSFRSR and Speech Anchor Questions.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65.3k/65.3k [00:00<00:00, 184kB/s, ALS History.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded ALS History.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101k/101k [00:00<00:00, 386kB/s, Blood Collection (ASSESS).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Blood Collection (ASSESS).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 581k/581k [00:00<00:00, 985kB/s, Concomitant Medication Log.csv] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Concomitant Medication Log.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.9k/15.9k [00:00<00:00, 44.4kB/s, Cerebral Spinal Fluid (CSF) Collection.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Cerebral Spinal Fluid (CSF) Collection.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55.8k/55.8k [00:00<00:00, 238kB/s, Demographics.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Demographics.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50.6k/50.6k [00:00<00:00, 143kB/s, Digital Speech Assessment.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Digital Speech Assessment.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63.5k/63.5k [00:00<00:00, 146kB/s, Digital Speech Assessment User Information.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Digital Speech Assessment User Information.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 142k/142k [00:00<00:00, 308kB/s, ECAS (Edinburgh Cognitive and Behavioral ALS Screen).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded ECAS (Edinburgh Cognitive and Behavioral ALS Screen).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 184k/184k [00:00<00:00, 427kB/s, ECAS (Edinburgh Cognitive and Behavioral ALS Screen) Caregiver Interview.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded ECAS (Edinburgh Cognitive and Behavioral ALS Screen) Caregiver Interview.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.9k/10.9k [00:00<00:00, 43.8kB/s, Lumbar Puncture Eligibility Confirmation.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Lumbar Puncture Eligibility Confirmation.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55.1k/55.1k [00:00<00:00, 211kB/s, Enrollment Confirmation.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Enrollment Confirmation.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.0k/17.0k [00:00<00:00, 67.8kB/s, Eligibility Criteria (ASSESS Control).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Eligibility Criteria (ASSESS Control).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54.0k/54.0k [00:00<00:00, 127kB/s, Eligibility Criteria (ASSESS Symptomatic).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Eligibility Criteria (ASSESS Symptomatic).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16.1k/16.1k [00:00<00:00, 50.5kB/s, Lumbar Puncture Eligibility Criteria.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Lumbar Puncture Eligibility Criteria.csv as version v3-DEC\n",
            "  ‚úì Uploaded Eligibility Criteria (ASSESS Control).csv as version v3-DEC\n",
            "  ‚úì Uploaded Eligibility Criteria (ASSESS Symptomatic).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 260k/260k [00:00<00:00, 600kB/s, Family History.csv] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Family History.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200k/200k [00:00<00:00, 388kB/s, Modified HandHeld Dynamometry (HHD).csv] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Modified HandHeld Dynamometry (HHD).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83.8k/83.8k [00:00<00:00, 303kB/s, Informed Consent Log.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Informed Consent Log.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91.5k/91.5k [00:00<00:00, 252kB/s, Key Devices and Procedures Log.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Key Devices and Procedures Log.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 390k/390k [00:00<00:00, 528kB/s, Medical History.csv] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Medical History.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13.1k/13.1k [00:00<00:00, 36.8kB/s, ASSESS Participant Final Disposition.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded ASSESS Participant Final Disposition.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 161k/161k [00:00<00:00, 362kB/s, Protocol Deviation Log.csv] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Protocol Deviation Log.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69.3k/69.3k [00:00<00:00, 177kB/s, Prior ALS Genetic Testing.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Prior ALS Genetic Testing.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107k/107k [00:00<00:00, 288kB/s, Vital Capacity (VC).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Vital Capacity (VC).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 122k/122k [00:00<00:00, 340kB/s, Visit Type.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Visit Type.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 94.0k/94.0k [00:00<00:00, 277kB/s, Vital Signs (ASSESS).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Vital Signs (ASSESS).csv as version v3-DEC\n",
            "\n",
            "Moving ASSESS new files...\n",
            "  ‚úì Moved v_ALLALS_AS_ASSEICFCSF.csv to release folder\n",
            "  ‚úì Renamed v_ALLALS_AS_ASSEICFCSF.csv ‚Üí Informed Consent Log CSF Collection.csv\n",
            "  ‚úì Added v_ALLALS_AS_ASSEICFCSF.csv to dataset\n",
            "  ‚úì Set annotations on v_ALLALS_AS_ASSEICFCSF.csv\n",
            "  ‚úì Moved v_ALLALS_AS_NPROREGASSESS.csv to release folder\n",
            "  ‚úì Renamed v_ALLALS_AS_NPROREGASSESS.csv ‚Üí NPROREGASSESS.csv\n",
            "  ‚úì Added v_ALLALS_AS_NPROREGASSESS.csv to dataset\n",
            "  ‚úì Set annotations on v_ALLALS_AS_NPROREGASSESS.csv\n",
            "\n",
            "--- PREVENT Dataset ---\n",
            "\n",
            "Uploading PREVENT matched files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.1k/15.1k [00:00<00:00, 34.0kB/s, Adverse Event (AE) Log.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Adverse Event (AE) Log.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42.5k/42.5k [00:00<00:00, 154kB/s, Blood Collection (PREVENT InClinic).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Blood Collection (PREVENT InClinic).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22.5k/22.5k [00:00<00:00, 53.3kB/s, Blood Collection (PREVENT Remote).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Blood Collection (PREVENT Remote).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167k/167k [00:00<00:00, 396kB/s, Concomitant Medication Log.csv] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Concomitant Medication Log.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.5k/18.5k [00:00<00:00, 44.6kB/s, Cerebral Spinal Fluid (CSF) Collection.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Cerebral Spinal Fluid (CSF) Collection.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.0k/18.0k [00:00<00:00, 76.0kB/s, Demographics.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Demographics.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37.8k/37.8k [00:00<00:00, 88.8kB/s, Digital Speech Assessment.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Digital Speech Assessment.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31.6k/31.6k [00:00<00:00, 125kB/s, Digital Speech Assessment User Information.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Digital Speech Assessment User Information.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74.6k/74.6k [00:00<00:00, 232kB/s, ECAS (Edinburgh Cognitive and Behavioral ALS Screen).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded ECAS (Edinburgh Cognitive and Behavioral ALS Screen).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89.6k/89.6k [00:00<00:00, 193kB/s, ECAS (Edinburgh Cognitive and Behavioral ALS Screen) Caregiver Interview.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded ECAS (Edinburgh Cognitive and Behavioral ALS Screen) Caregiver Interview.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.8k/12.8k [00:00<00:00, 57.2kB/s, Enrollment Confirmation (PREVENT Genetic Testing SubStudy).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Enrollment Confirmation (PREVENT Genetic Testing SubStudy).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.7k/17.7k [00:00<00:00, 50.4kB/s, Lumbar Puncture Eligibility Confirmation.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Lumbar Puncture Eligibility Confirmation.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25.8k/25.8k [00:00<00:00, 126kB/s, Enrollment Confirmation.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Enrollment Confirmation.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34.0k/34.0k [00:00<00:00, 104kB/s, Eligibility Criteria (PREVENT).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Eligibility Criteria (PREVENT).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.00k/5.00k [00:00<00:00, 14.1kB/s, Eligibility Criteria (PREVENT Genetic Testing SubStudy).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Eligibility Criteria (PREVENT Genetic Testing SubStudy).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26.7k/26.7k [00:00<00:00, 116kB/s, Lumbar Puncture Eligibility Criteria.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Lumbar Puncture Eligibility Criteria.csv as version v3-DEC\n",
            "  ‚úì Uploaded Eligibility Criteria (PREVENT).csv as version v3-DEC\n",
            "  ‚úì Uploaded Eligibility Criteria (PREVENT Genetic Testing SubStudy).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.9k/17.9k [00:00<00:00, 76.9kB/s, EMG.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded EMG.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43.9k/43.9k [00:00<00:00, 197kB/s, PREVENT End of Visit Form.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded PREVENT End of Visit Form.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274k/274k [00:00<00:00, 607kB/s, Family History.csv] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Family History.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37.2k/37.2k [00:00<00:00, 145kB/s, Genetic Counseling Referral.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Genetic Counseling Referral.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36.6k/36.6k [00:00<00:00, 139kB/s, ALS Gene Carrier Research Participation Log.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded ALS Gene Carrier Research Participation Log.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.13k/7.13k [00:00<00:00, 32.7kB/s, PREVENT Genetic Testing Results.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded PREVENT Genetic Testing Results.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45.4k/45.4k [00:00<00:00, 156kB/s, Grip Strength Testing.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Grip Strength Testing.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42.7k/42.7k [00:00<00:00, 115kB/s, Informed Consent Log.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Informed Consent Log.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25.7k/25.7k [00:00<00:00, 111kB/s, Key Devices and Procedures Log.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Key Devices and Procedures Log.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 194k/194k [00:00<00:00, 607kB/s, Medical History.csv] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Medical History.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.8k/17.8k [00:00<00:00, 76.9kB/s, MIR (Participant).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded MIR (Participant).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65.9k/65.9k [00:00<00:00, 200kB/s, MIR Screener (Participant).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded MIR Screener (Participant).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.7k/18.7k [00:00<00:00, 91.3kB/s, MIR Screener (Study Partner).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded MIR Screener (Study Partner).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.0k/18.0k [00:00<00:00, 78.7kB/s, MIR (Study Partner).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded MIR (Study Partner).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 385k/385k [00:00<00:00, 645kB/s, Neurological Examination.csv] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Neurological Examination.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.09k/4.09k [00:00<00:00, 18.4kB/s, PREVENT Participant Final Disposition.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded PREVENT Participant Final Disposition.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112k/112k [00:00<00:00, 366kB/s, Protocol Deviation Log.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Protocol Deviation Log.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.96k/6.96k [00:00<00:00, 30.6kB/s, Phenoconversion.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Phenoconversion.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.72k/1.72k [00:00<00:00, 8.06kB/s, Physical Examination.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Physical Examination.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.2k/44.2k [00:00<00:00, 121kB/s, Prior ALS Genetic Testing.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Prior ALS Genetic Testing.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22.9k/22.9k [00:00<00:00, 76.3kB/s, PREVENT Symptom Questionnaire.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded PREVENT Symptom Questionnaire.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55.2k/55.2k [00:00<00:00, 147kB/s, Vital Capacity (VC).csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Vital Capacity (VC).csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67.6k/67.6k [00:00<00:00, 185kB/s, Visit Type.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Visit Type.csv as version v3-DEC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading to Synapse storage: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.6k/12.6k [00:00<00:00, 34.7kB/s, Weight.csv]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ‚úì Uploaded Weight.csv as version v3-DEC\n",
            "\n",
            "Moving PREVENT new files...\n",
            "  ‚úì Moved v_ALLALS_PR_NPROREG.csv to release folder\n",
            "  ‚úì Renamed v_ALLALS_PR_NPROREG.csv ‚Üí NPROREG.csv\n",
            "  ‚úì Added v_ALLALS_PR_NPROREG.csv to dataset\n",
            "  ‚úì Set annotations on v_ALLALS_PR_NPROREG.csv\n",
            "  ‚úì Moved v_ALLALS_PR_PREVFUTELEV.csv to release folder\n",
            "  ‚úì Renamed v_ALLALS_PR_PREVFUTELEV.csv ‚Üí FollowUp Telephone Visit.csv\n",
            "  ‚úì Added v_ALLALS_PR_PREVFUTELEV.csv to dataset\n",
            "  ‚úì Set annotations on v_ALLALS_PR_PREVFUTELEV.csv\n",
            "  ‚úì Moved v_ALLALS_PR_PREVHHD.csv to release folder\n",
            "  ‚úì Renamed v_ALLALS_PR_PREVHHD.csv ‚Üí Handheld Dynamometry (HHD).csv\n",
            "  ‚úì Added v_ALLALS_PR_PREVHHD.csv to dataset\n",
            "  ‚úì Set annotations on v_ALLALS_PR_PREVHHD.csv\n",
            "  ‚úì Moved v_ALLALS_PR_PREVICFGEN.csv to release folder\n",
            "  ‚úì Renamed v_ALLALS_PR_PREVICFGEN.csv ‚Üí Informed Consent Log Genetic Testing SubStudy.csv\n",
            "  ‚úì Added v_ALLALS_PR_PREVICFGEN.csv to dataset\n",
            "  ‚úì Set annotations on v_ALLALS_PR_PREVICFGEN.csv\n",
            "  ‚úì Moved v_ALLALS_PR_PREVOGCVH.csv to release folder\n",
            "  ‚úì Renamed v_ALLALS_PR_PREVOGCVH.csv ‚Üí Optional Genetic Counseling Visit History.csv\n",
            "  ‚úì Added v_ALLALS_PR_PREVOGCVH.csv to dataset\n",
            "  ‚úì Set annotations on v_ALLALS_PR_PREVOGCVH.csv\n",
            "  ‚úì Moved v_ALLALS_PR_PREVPREGENCONAP.csv to release folder\n",
            "  ‚úì Renamed v_ALLALS_PR_PREVPREGENCONAP.csv ‚Üí PreTest Genetic Counseling Appointment.csv\n",
            "  ‚úì Added v_ALLALS_PR_PREVPREGENCONAP.csv to dataset\n",
            "  ‚úì Set annotations on v_ALLALS_PR_PREVPREGENCONAP.csv\n",
            "  ‚úì Moved v_ALLALS_PR_PREVPSTGENCONAP.csv to release folder\n",
            "  ‚úì Renamed v_ALLALS_PR_PREVPSTGENCONAP.csv ‚Üí Return of Genetic Results Counseling Appointment.csv\n",
            "  ‚úì Added v_ALLALS_PR_PREVPSTGENCONAP.csv to dataset\n",
            "  ‚úì Set annotations on v_ALLALS_PR_PREVPSTGENCONAP.csv\n",
            "  ‚úì Moved v_ALLALS_PR_PREVVITSIGN.csv to release folder\n",
            "  ‚úì Renamed v_ALLALS_PR_PREVVITSIGN.csv ‚Üí Vital Signs (PREVENT).csv\n",
            "  ‚úì Added v_ALLALS_PR_PREVVITSIGN.csv to dataset\n",
            "  ‚úì Set annotations on v_ALLALS_PR_PREVVITSIGN.csv\n",
            "\n",
            "============================================================\n",
            "OPERATION RESULTS\n",
            "============================================================\n",
            "\n",
            "ASSESS:\n",
            "  Uploads (new versions):\n",
            "    ‚úì Success: 30\n",
            "    ‚úó Errors: 0\n",
            "    ‚ö†Ô∏è  Skipped: 0\n",
            "  Moves (new files):\n",
            "    ‚úì Success: 2\n",
            "    ‚úó Errors: 0\n",
            "    ‚ö†Ô∏è  Skipped: 0\n",
            "\n",
            "PREVENT:\n",
            "  Uploads (new versions):\n",
            "    ‚úì Success: 42\n",
            "    ‚úó Errors: 0\n",
            "    ‚ö†Ô∏è  Skipped: 0\n",
            "  Moves (new files):\n",
            "    ‚úì Success: 8\n",
            "    ‚úó Errors: 0\n",
            "    ‚ö†Ô∏è  Skipped: 0\n",
            "\n",
            "============================================================\n",
            "‚úÖ ALL OPERATIONS SUCCESSFUL\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def upload_file_version(syn, syn_id, file_path, filename, version_label, version_comment, annotations, dry_run=True):\n",
        "    \"\"\"\n",
        "    Upload a new version of a file to Synapse.\n",
        "    Returns: (success, error_message)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Clean annotations (remove metadata)\n",
        "        cleaned_annotations = clean_annotations_for_synapse(annotations)\n",
        "\n",
        "        if dry_run:\n",
        "            print(f\"  [DRY_RUN] Would upload:\")\n",
        "            print(f\"    - File: {file_path}\")\n",
        "            print(f\"    - To: {syn_id}\")\n",
        "            print(f\"    - Version: {version_label}\")\n",
        "            print(f\"    - Annotations: {len(cleaned_annotations)} fields\")\n",
        "            return (True, None)\n",
        "\n",
        "        # Create File object with annotations\n",
        "        file_entity = File(\n",
        "            path=file_path,\n",
        "            id=syn_id,\n",
        "            version_comment=version_comment,\n",
        "            version_label=version_label,\n",
        "            annotations=cleaned_annotations\n",
        "        )\n",
        "\n",
        "        # Upload to Synapse using new API\n",
        "        file_entity = file_entity.store()\n",
        "\n",
        "        if VERBOSE:\n",
        "            print(f\"  ‚úì Uploaded {filename} as version {version_label}\")\n",
        "\n",
        "        return (True, None)\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Failed to upload {filename}: {e}\"\n",
        "        print(f\"  ‚úó {error_msg}\")\n",
        "        return (False, error_msg)\n",
        "\n",
        "\n",
        "def process_file_uploads(syn, file_annotations, rename_map, matched, dataset_name, dry_run=True):\n",
        "    \"\"\"\n",
        "    Process all file uploads for matched files (creates new versions).\n",
        "    Returns: (success_count, error_count, skipped_count, results)\n",
        "    \"\"\"\n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "    skipped_count = 0\n",
        "    results = []\n",
        "\n",
        "    for staging_syn_id, release_syn_id, local_path, form_name in matched:\n",
        "        # Get staged file path\n",
        "        if form_name not in rename_map:\n",
        "            print(f\"  ‚ö†Ô∏è  Skipping {form_name} (not found in rename map)\")\n",
        "            skipped_count += 1\n",
        "            continue\n",
        "\n",
        "        renamed_filename, staged_path = rename_map[form_name]\n",
        "\n",
        "        # Get annotations for this file\n",
        "        if release_syn_id not in file_annotations:\n",
        "            print(f\"  ‚ö†Ô∏è  Skipping {form_name} (no annotations found)\")\n",
        "            skipped_count += 1\n",
        "            continue\n",
        "\n",
        "        file_data = file_annotations[release_syn_id]\n",
        "        annotations = list(file_data.values())[0]  # Get first (and only) annotation dict\n",
        "\n",
        "        # Upload file to RELEASE syn_id (creates new version)\n",
        "        success, error = upload_file_version(\n",
        "            syn, release_syn_id, staged_path, renamed_filename,\n",
        "            VERSION_LABEL, VERSION_COMMENT, annotations, dry_run\n",
        "        )\n",
        "\n",
        "        if success:\n",
        "            success_count += 1\n",
        "        else:\n",
        "            error_count += 1\n",
        "\n",
        "        results.append({\n",
        "            'filename': renamed_filename,\n",
        "            'syn_id': release_syn_id,\n",
        "            'success': success,\n",
        "            'error': error\n",
        "        })\n",
        "\n",
        "    return success_count, error_count, skipped_count, results\n",
        "\n",
        "\n",
        "def process_new_file_moves(\n",
        "    syn, file_annotations, new_only, \n",
        "    release_folder_syn_id, dataset_syn_id, \n",
        "    dataset_name, dry_run=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Process moving new files from staging folder to release folder.\n",
        "    Returns: (success_count, error_count, skipped_count, results)\n",
        "    \"\"\"\n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "    skipped_count = 0\n",
        "    results = []\n",
        "\n",
        "    for staging_syn_id, filename, form_name in new_only:\n",
        "        if not staging_syn_id:\n",
        "            # Local file only - needs manual entity creation\n",
        "            print(f\"  ‚ö†Ô∏è  Skipping {filename} (local file - create entity first)\")\n",
        "            skipped_count += 1\n",
        "            continue\n",
        "\n",
        "        # Get annotations for this file\n",
        "        if staging_syn_id not in file_annotations:\n",
        "            print(f\"  ‚ö†Ô∏è  Skipping {filename} (no annotations found)\")\n",
        "            skipped_count += 1\n",
        "            continue\n",
        "\n",
        "        file_data = file_annotations[staging_syn_id]\n",
        "        annotations = list(file_data.values())[0]\n",
        "\n",
        "        # Move file to release folder + add to dataset + set annotations\n",
        "        success, error = move_file_to_release(\n",
        "            syn, staging_syn_id, release_folder_syn_id, \n",
        "            dataset_syn_id, annotations, form_name, dry_run\n",
        "        )\n",
        "\n",
        "        if success:\n",
        "            success_count += 1\n",
        "        else:\n",
        "            error_count += 1\n",
        "\n",
        "        results.append({\n",
        "            'filename': filename,\n",
        "            'syn_id': staging_syn_id,\n",
        "            'success': success,\n",
        "            'error': error\n",
        "        })\n",
        "\n",
        "    return success_count, error_count, skipped_count, results\n",
        "\n",
        "\n",
        "# Upload and move files\n",
        "print(\"=\" * 60)\n",
        "print(f\"UPLOADING FILES AND MOVING NEW FILES (DRY_RUN={DRY_RUN})\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if DRY_RUN:\n",
        "    print(\"\\n‚ö†Ô∏è  DRY_RUN MODE - No files will be uploaded or moved\")\n",
        "    print(\"Set DRY_RUN=False in configuration to actually execute\\n\")\n",
        "\n",
        "# Connect to Synapse (needed even in DRY_RUN for file info)\n",
        "if 'syn' not in globals() or syn is None:\n",
        "    syn = connect_to_synapse()\n",
        "\n",
        "# ========== ASSESS ==========\n",
        "print(\"\\n--- ASSESS Dataset ---\")\n",
        "\n",
        "# Upload matched files (update with new versions)\n",
        "print(f\"\\nUploading ASSESS matched files...\")\n",
        "assess_upload_success, assess_upload_errors, assess_upload_skipped, assess_upload_results = process_file_uploads(\n",
        "    syn, assess_file_annotations, assess_rename_map,\n",
        "    assess_matched, 'ASSESS', DRY_RUN\n",
        ")\n",
        "\n",
        "# Move new files (if using Synapse staging)\n",
        "assess_move_success = 0\n",
        "assess_move_errors = 0\n",
        "assess_move_skipped = 0\n",
        "assess_move_results = []\n",
        "\n",
        "if USE_SYNAPSE_STAGING and assess_new_only:\n",
        "    print(f\"\\nMoving ASSESS new files...\")\n",
        "    assess_move_success, assess_move_errors, assess_move_skipped, assess_move_results = process_new_file_moves(\n",
        "        syn, assess_file_annotations, assess_new_only,\n",
        "        ASSESS_RELEASE_FOLDER_SYN_ID, ASSESS_DATASET_SYN_ID,\n",
        "        'ASSESS', DRY_RUN\n",
        "    )\n",
        "elif assess_new_only:\n",
        "    print(f\"\\n‚ö†Ô∏è  {len(assess_new_only)} new ASSESS files (local workflow - create entities manually)\")\n",
        "\n",
        "# ========== PREVENT ==========\n",
        "print(\"\\n--- PREVENT Dataset ---\")\n",
        "\n",
        "# Upload matched files (update with new versions)\n",
        "print(f\"\\nUploading PREVENT matched files...\")\n",
        "prevent_upload_success, prevent_upload_errors, prevent_upload_skipped, prevent_upload_results = process_file_uploads(\n",
        "    syn, prevent_file_annotations, prevent_rename_map,\n",
        "    prevent_matched, 'PREVENT', DRY_RUN\n",
        ")\n",
        "\n",
        "# Move new files (if using Synapse staging)\n",
        "prevent_move_success = 0\n",
        "prevent_move_errors = 0\n",
        "prevent_move_skipped = 0\n",
        "prevent_move_results = []\n",
        "\n",
        "if USE_SYNAPSE_STAGING and prevent_new_only:\n",
        "    print(f\"\\nMoving PREVENT new files...\")\n",
        "    prevent_move_success, prevent_move_errors, prevent_move_skipped, prevent_move_results = process_new_file_moves(\n",
        "        syn, prevent_file_annotations, prevent_new_only,\n",
        "        PREVENT_RELEASE_FOLDER_SYN_ID, PREVENT_DATASET_SYN_ID,\n",
        "        'PREVENT', DRY_RUN\n",
        "    )\n",
        "elif prevent_new_only:\n",
        "    print(f\"\\n‚ö†Ô∏è  {len(prevent_new_only)} new PREVENT files (local workflow - create entities manually)\")\n",
        "\n",
        "# ========== SUMMARY ==========\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"OPERATION RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nASSESS:\")\n",
        "print(f\"  Uploads (new versions):\")\n",
        "print(f\"    ‚úì Success: {assess_upload_success}\")\n",
        "print(f\"    ‚úó Errors: {assess_upload_errors}\")\n",
        "print(f\"    ‚ö†Ô∏è  Skipped: {assess_upload_skipped}\")\n",
        "if USE_SYNAPSE_STAGING:\n",
        "    print(f\"  Moves (new files):\")\n",
        "    print(f\"    ‚úì Success: {assess_move_success}\")\n",
        "    print(f\"    ‚úó Errors: {assess_move_errors}\")\n",
        "    print(f\"    ‚ö†Ô∏è  Skipped: {assess_move_skipped}\")\n",
        "\n",
        "print(f\"\\nPREVENT:\")\n",
        "print(f\"  Uploads (new versions):\")\n",
        "print(f\"    ‚úì Success: {prevent_upload_success}\")\n",
        "print(f\"    ‚úó Errors: {prevent_upload_errors}\")\n",
        "print(f\"    ‚ö†Ô∏è  Skipped: {prevent_upload_skipped}\")\n",
        "if USE_SYNAPSE_STAGING:\n",
        "    print(f\"  Moves (new files):\")\n",
        "    print(f\"    ‚úì Success: {prevent_move_success}\")\n",
        "    print(f\"    ‚úó Errors: {prevent_move_errors}\")\n",
        "    print(f\"    ‚ö†Ô∏è  Skipped: {prevent_move_skipped}\")\n",
        "\n",
        "# Show any errors\n",
        "all_results = assess_upload_results + assess_move_results + prevent_upload_results + prevent_move_results\n",
        "error_results = [r for r in all_results if not r['success']]\n",
        "\n",
        "if error_results:\n",
        "    print(\"\\n‚ùå Errors:\")\n",
        "    for result in error_results:\n",
        "        print(f\"  - {result['filename']}: {result['error']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "if DRY_RUN:\n",
        "    print(\"‚úì DRY_RUN COMPLETE - Set DRY_RUN=False to actually execute\")\n",
        "elif not error_results:\n",
        "    print(\"‚úÖ ALL OPERATIONS SUCCESSFUL\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  OPERATIONS COMPLETED WITH ERRORS\")\n",
        "\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Verify Uploads\n",
        "\n",
        "Verify successful uploads by checking file versions and annotations in Synapse.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "VERIFYING OPERATIONS\n",
            "============================================================\n",
            "\n",
            "Connecting to Synapse...\n",
            "\n",
            "--- ASSESS Dataset ---\n",
            "\n",
            "Verifying ASSESS file versions...\n",
            "  ‚úì Adverse Event (AE) Log: version v3-DEC\n",
            "  ‚úì ALSFRS-R: version v3-DEC\n",
            "  ‚úì ALSFRS-R and Speech Anchor Questions: version v3-DEC\n",
            "  ‚úì ALS History: version v3-DEC\n",
            "  ‚úì Blood Collection (ASSESS): version v3-DEC\n",
            "  ‚úì Concomitant Medication Log: version v3-DEC\n",
            "  ‚úì Cerebral Spinal Fluid (CSF) Collection: version v3-DEC\n",
            "  ‚úì Demographics: version v3-DEC\n",
            "  ‚úì Digital Speech Assessment: version v3-DEC\n",
            "  ‚úì Digital Speech Assessment User Information: version v3-DEC\n",
            "  ‚úì ECAS (Edinburgh Cognitive and Behavioral ALS Screen): version v3-DEC\n",
            "  ‚úì ECAS (Edinburgh Cognitive and Behavioral ALS Screen) - Caregiver Interview: version v3-DEC\n",
            "  ‚úì Lumbar Puncture Eligibility Confirmation: version v3-DEC\n",
            "  ‚úì Enrollment Confirmation: version v3-DEC\n",
            "  ‚úì Eligibility Criteria (ASSESS Control): version v3-DEC\n",
            "  ‚úì Eligibility Criteria (ASSESS Symptomatic): version v3-DEC\n",
            "  ‚úì Lumbar Puncture Eligibility Criteria: version v3-DEC\n",
            "  ‚úì Eligibility Criteria (ASSESS Control): version v3-DEC\n",
            "  ‚úì Eligibility Criteria (ASSESS Symptomatic): version v3-DEC\n",
            "  ‚úì Family History: version v3-DEC\n",
            "  ‚úì Modified Hand-Held Dynamometry (HHD): version v3-DEC\n",
            "  ‚úì Informed Consent Log: version v3-DEC\n",
            "  ‚úì Key Devices and Procedures Log: version v3-DEC\n",
            "  ‚úì Medical History: version v3-DEC\n",
            "  ‚úì ASSESS Participant Final Disposition: version v3-DEC\n",
            "  ‚úì Protocol Deviation Log: version v3-DEC\n",
            "  ‚úì Prior ALS Genetic Testing: version v3-DEC\n",
            "  ‚úì Vital Capacity (VC): version v3-DEC\n",
            "  ‚úì Visit Type: version v3-DEC\n",
            "  ‚úì Vital Signs (ASSESS): version v3-DEC\n",
            "\n",
            "Verifying ASSESS file moves...\n",
            "  ‚úì Informed Consent Log: CSF Collection: moved and in dataset\n",
            "  ‚úì NPROREGASSESS: moved and in dataset\n",
            "\n",
            "--- PREVENT Dataset ---\n",
            "\n",
            "Verifying PREVENT file versions...\n",
            "  ‚úì Adverse Event (AE) Log: version v3-DEC\n",
            "  ‚úì Blood Collection (PREVENT In-Clinic): version v3-DEC\n",
            "  ‚úì Blood Collection (PREVENT Remote): version v3-DEC\n",
            "  ‚úì Concomitant Medication Log: version v3-DEC\n",
            "  ‚úì Cerebral Spinal Fluid (CSF) Collection: version v3-DEC\n",
            "  ‚úì Demographics: version v3-DEC\n",
            "  ‚úì Digital Speech Assessment: version v3-DEC\n",
            "  ‚úì Digital Speech Assessment User Information: version v3-DEC\n",
            "  ‚úì ECAS (Edinburgh Cognitive and Behavioral ALS Screen): version v3-DEC\n",
            "  ‚úì ECAS (Edinburgh Cognitive and Behavioral ALS Screen) - Caregiver Interview: version v3-DEC\n",
            "  ‚úì Enrollment Confirmation (PREVENT Genetic Testing Sub-Study): version v3-DEC\n",
            "  ‚úì Lumbar Puncture Eligibility Confirmation: version v3-DEC\n",
            "  ‚úì Enrollment Confirmation: version v3-DEC\n",
            "  ‚úì Eligibility Criteria (PREVENT): version v3-DEC\n",
            "  ‚úì Eligibility Criteria (PREVENT Genetic Testing Sub-Study): version v3-DEC\n",
            "  ‚úì Lumbar Puncture Eligibility Criteria: version v3-DEC\n",
            "  ‚úì Eligibility Criteria (PREVENT): version v3-DEC\n",
            "  ‚úì Eligibility Criteria (PREVENT Genetic Testing Sub-Study): version v3-DEC\n",
            "  ‚úì EMG: version v3-DEC\n",
            "  ‚úì PREVENT End of Visit Form: version v3-DEC\n",
            "  ‚úì Family History: version v3-DEC\n",
            "  ‚úì Genetic Counseling Referral: version v3-DEC\n",
            "  ‚úì ALS Gene Carrier Research Participation Log: version v3-DEC\n",
            "  ‚úì PREVENT Genetic Testing Results: version v3-DEC\n",
            "  ‚úì Grip Strength Testing: version v3-DEC\n",
            "  ‚úì Informed Consent Log: version v3-DEC\n",
            "  ‚úì Key Devices and Procedures Log: version v3-DEC\n",
            "  ‚úì Medical History: version v3-DEC\n",
            "  ‚úì MIR (Participant): version v3-DEC\n",
            "  ‚úì MIR Screener (Participant): version v3-DEC\n",
            "  ‚úì MIR Screener (Study Partner): version v3-DEC\n",
            "  ‚úì MIR (Study Partner): version v3-DEC\n",
            "  ‚úì Neurological Examination: version v3-DEC\n",
            "  ‚úì PREVENT Participant Final Disposition: version v3-DEC\n",
            "  ‚úì Protocol Deviation Log: version v3-DEC\n",
            "  ‚úì Phenoconversion: version v3-DEC\n",
            "  ‚úì Physical Examination: version v3-DEC\n",
            "  ‚úì Prior ALS Genetic Testing: version v3-DEC\n",
            "  ‚úì PREVENT Symptom Questionnaire: version v3-DEC\n",
            "  ‚úì Vital Capacity (VC): version v3-DEC\n",
            "  ‚úì Visit Type: version v3-DEC\n",
            "  ‚úì Weight: version v3-DEC\n",
            "\n",
            "Verifying PREVENT file moves...\n",
            "  ‚úì NPROREG: moved and in dataset\n",
            "  ‚úì Follow-Up Telephone Visit: moved and in dataset\n",
            "  ‚úì Handheld Dynamometry (HHD): moved and in dataset\n",
            "  ‚úì Informed Consent Log: Genetic Testing Sub-Study: moved and in dataset\n",
            "  ‚úì Optional Genetic Counseling Visit History: moved and in dataset\n",
            "  ‚úì Pre-Test Genetic Counseling Appointment: moved and in dataset\n",
            "  ‚úì Return of Genetic Results Counseling Appointment: moved and in dataset\n",
            "  ‚úì Vital Signs (PREVENT): moved and in dataset\n",
            "\n",
            "============================================================\n",
            "VERIFICATION RESULTS\n",
            "============================================================\n",
            "\n",
            "ASSESS:\n",
            "  Uploads verified: 30 files\n",
            "  Moves verified: 2 files\n",
            "\n",
            "PREVENT:\n",
            "  Uploads verified: 42 files\n",
            "  Moves verified: 8 files\n",
            "\n",
            "============================================================\n",
            "‚úÖ ALL OPERATIONS VERIFIED SUCCESSFULLY\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "WORKFLOW COMPLETE\n",
            "============================================================\n",
            "Summary:\n",
            "  - ASSESS files processed: 30 updated\n",
            "  - ASSESS new files: 2 moved\n",
            "  - PREVENT files processed: 42 updated\n",
            "  - PREVENT new files: 8 moved\n",
            "  - Version: v3-DEC\n",
            "  - Workflow mode: Synapse-based\n",
            "  - DRY_RUN: False\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "def verify_file_version(syn, syn_id, expected_version_label):\n",
        "    \"\"\"\n",
        "    Verify that a file has the expected version label.\n",
        "    Returns: (success, actual_version)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        entity = syn.get(syn_id, downloadFile=False)\n",
        "        actual_version = entity.versionLabel if hasattr(entity, 'versionLabel') else None\n",
        "\n",
        "        if actual_version == expected_version_label:\n",
        "            return (True, actual_version)\n",
        "        else:\n",
        "            return (False, actual_version)\n",
        "\n",
        "    except Exception as e:\n",
        "        if VERBOSE:\n",
        "            print(f\"  ‚ö†Ô∏è  Could not verify {syn_id}: {e}\")\n",
        "        return (False, None)\n",
        "\n",
        "\n",
        "def verify_file_parent(syn, syn_id, expected_parent_id):\n",
        "    \"\"\"\n",
        "    Verify that a file has the expected parent folder.\n",
        "    Returns: (success, actual_parent_id)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        entity = syn.get(syn_id, downloadFile=False)\n",
        "        actual_parent = entity.parentId if hasattr(entity, 'parentId') else None\n",
        "\n",
        "        if actual_parent == expected_parent_id:\n",
        "            return (True, actual_parent)\n",
        "        else:\n",
        "            return (False, actual_parent)\n",
        "\n",
        "    except Exception as e:\n",
        "        if VERBOSE:\n",
        "            print(f\"  ‚ö†Ô∏è  Could not verify parent for {syn_id}: {e}\")\n",
        "        return (False, None)\n",
        "\n",
        "\n",
        "def verify_file_in_dataset(syn, dataset_syn_id, file_syn_id):\n",
        "    \"\"\"\n",
        "    Verify that a file is in the dataset.\n",
        "    Returns: (success, is_in_dataset)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        dataset = Dataset(dataset_syn_id).get()\n",
        "        file_ids = [item.id for item in dataset.items]\n",
        "        \n",
        "        is_in_dataset = file_syn_id in file_ids\n",
        "        return (is_in_dataset, is_in_dataset)\n",
        "\n",
        "    except Exception as e:\n",
        "        if VERBOSE:\n",
        "            print(f\"  ‚ö†Ô∏è  Could not verify dataset membership: {e}\")\n",
        "        return (False, False)\n",
        "\n",
        "\n",
        "def verify_uploads(syn, matched, expected_version_label, dataset_name):\n",
        "    \"\"\"\n",
        "    Verify all uploads for a dataset.\n",
        "    Returns: (verified_count, errors)\n",
        "    \"\"\"\n",
        "    verified_count = 0\n",
        "    errors = []\n",
        "\n",
        "    for staging_syn_id, release_syn_id, local_path, form_name in matched:\n",
        "        success, actual_version = verify_file_version(syn, release_syn_id, expected_version_label)\n",
        "\n",
        "        if success:\n",
        "            verified_count += 1\n",
        "            if VERBOSE:\n",
        "                print(f\"  ‚úì {form_name}: version {actual_version}\")\n",
        "        else:\n",
        "            error_msg = f\"{form_name}: expected {expected_version_label}, got {actual_version}\"\n",
        "            errors.append(error_msg)\n",
        "            print(f\"  ‚úó {error_msg}\")\n",
        "\n",
        "    return verified_count, errors\n",
        "\n",
        "\n",
        "def verify_moves(syn, new_only, release_folder_syn_id, dataset_syn_id, dataset_name):\n",
        "    \"\"\"\n",
        "    Verify all file moves for a dataset.\n",
        "    Returns: (verified_count, parent_errors, dataset_errors)\n",
        "    \"\"\"\n",
        "    verified_count = 0\n",
        "    parent_errors = []\n",
        "    dataset_errors = []\n",
        "\n",
        "    for staging_syn_id, filename, form_name in new_only:\n",
        "        if not staging_syn_id:\n",
        "            continue  # Skip local-only files\n",
        "        \n",
        "        # Verify parent folder\n",
        "        parent_success, actual_parent = verify_file_parent(syn, staging_syn_id, release_folder_syn_id)\n",
        "        \n",
        "        if not parent_success:\n",
        "            error_msg = f\"{form_name}: expected parent {release_folder_syn_id}, got {actual_parent}\"\n",
        "            parent_errors.append(error_msg)\n",
        "            print(f\"  ‚úó Parent: {error_msg}\")\n",
        "        \n",
        "        # Verify dataset membership\n",
        "        dataset_success, in_dataset = verify_file_in_dataset(syn, dataset_syn_id, staging_syn_id)\n",
        "        \n",
        "        if not dataset_success or not in_dataset:\n",
        "            error_msg = f\"{form_name}: not in dataset {dataset_syn_id}\"\n",
        "            dataset_errors.append(error_msg)\n",
        "            print(f\"  ‚úó Dataset: {error_msg}\")\n",
        "        \n",
        "        # If both checks pass, count as verified\n",
        "        if parent_success and dataset_success:\n",
        "            verified_count += 1\n",
        "            if VERBOSE:\n",
        "                print(f\"  ‚úì {form_name}: moved and in dataset\")\n",
        "\n",
        "    return verified_count, parent_errors, dataset_errors\n",
        "\n",
        "\n",
        "# Verify uploads and moves\n",
        "print(\"=\" * 60)\n",
        "print(\"VERIFYING OPERATIONS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if DRY_RUN:\n",
        "    print(\"\\n‚ö†Ô∏è  Skipping verification (DRY_RUN mode)\")\n",
        "    print(\"=\" * 60)\n",
        "else:\n",
        "    print(f\"\\nConnecting to Synapse...\")\n",
        "    if 'syn' not in globals():\n",
        "        syn = connect_to_synapse()\n",
        "\n",
        "    # ========== ASSESS ==========\n",
        "    print(\"\\n--- ASSESS Dataset ---\")\n",
        "    \n",
        "    # Verify uploads (new versions)\n",
        "    print(f\"\\nVerifying ASSESS file versions...\")\n",
        "    assess_verified, assess_version_errors = verify_uploads(\n",
        "        syn, assess_matched, VERSION_LABEL, 'ASSESS'\n",
        "    )\n",
        "\n",
        "    # Verify moves (new files)\n",
        "    assess_moves_verified = 0\n",
        "    assess_parent_errors = []\n",
        "    assess_dataset_errors = []\n",
        "    \n",
        "    if USE_SYNAPSE_STAGING and assess_new_only:\n",
        "        print(f\"\\nVerifying ASSESS file moves...\")\n",
        "        assess_moves_verified, assess_parent_errors, assess_dataset_errors = verify_moves(\n",
        "            syn, assess_new_only, ASSESS_RELEASE_FOLDER_SYN_ID, ASSESS_DATASET_SYN_ID, 'ASSESS'\n",
        "        )\n",
        "\n",
        "    # ========== PREVENT ==========\n",
        "    print(\"\\n--- PREVENT Dataset ---\")\n",
        "    \n",
        "    # Verify uploads (new versions)\n",
        "    print(f\"\\nVerifying PREVENT file versions...\")\n",
        "    prevent_verified, prevent_version_errors = verify_uploads(\n",
        "        syn, prevent_matched, VERSION_LABEL, 'PREVENT'\n",
        "    )\n",
        "\n",
        "    # Verify moves (new files)\n",
        "    prevent_moves_verified = 0\n",
        "    prevent_parent_errors = []\n",
        "    prevent_dataset_errors = []\n",
        "    \n",
        "    if USE_SYNAPSE_STAGING and prevent_new_only:\n",
        "        print(f\"\\nVerifying PREVENT file moves...\")\n",
        "        prevent_moves_verified, prevent_parent_errors, prevent_dataset_errors = verify_moves(\n",
        "            syn, prevent_new_only, PREVENT_RELEASE_FOLDER_SYN_ID, PREVENT_DATASET_SYN_ID, 'PREVENT'\n",
        "        )\n",
        "\n",
        "    # ========== SUMMARY ==========\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"VERIFICATION RESULTS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(f\"\\nASSESS:\")\n",
        "    print(f\"  Uploads verified: {assess_verified} files\")\n",
        "    if assess_version_errors:\n",
        "        print(f\"  ‚úó Version errors: {len(assess_version_errors)}\")\n",
        "        for error in assess_version_errors:\n",
        "            print(f\"    - {error}\")\n",
        "    \n",
        "    if USE_SYNAPSE_STAGING:\n",
        "        print(f\"  Moves verified: {assess_moves_verified} files\")\n",
        "        if assess_parent_errors:\n",
        "            print(f\"  ‚úó Parent folder errors: {len(assess_parent_errors)}\")\n",
        "            for error in assess_parent_errors:\n",
        "                print(f\"    - {error}\")\n",
        "        if assess_dataset_errors:\n",
        "            print(f\"  ‚úó Dataset membership errors: {len(assess_dataset_errors)}\")\n",
        "            for error in assess_dataset_errors:\n",
        "                print(f\"    - {error}\")\n",
        "\n",
        "    print(f\"\\nPREVENT:\")\n",
        "    print(f\"  Uploads verified: {prevent_verified} files\")\n",
        "    if prevent_version_errors:\n",
        "        print(f\"  ‚úó Version errors: {len(prevent_version_errors)}\")\n",
        "        for error in prevent_version_errors:\n",
        "            print(f\"    - {error}\")\n",
        "    \n",
        "    if USE_SYNAPSE_STAGING:\n",
        "        print(f\"  Moves verified: {prevent_moves_verified} files\")\n",
        "        if prevent_parent_errors:\n",
        "            print(f\"  ‚úó Parent folder errors: {len(prevent_parent_errors)}\")\n",
        "            for error in prevent_parent_errors:\n",
        "                print(f\"    - {error}\")\n",
        "        if prevent_dataset_errors:\n",
        "            print(f\"  ‚úó Dataset membership errors: {len(prevent_dataset_errors)}\")\n",
        "            for error in prevent_dataset_errors:\n",
        "                print(f\"    - {error}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "    # Overall status\n",
        "    all_errors = (assess_version_errors + assess_parent_errors + assess_dataset_errors +\n",
        "                  prevent_version_errors + prevent_parent_errors + prevent_dataset_errors)\n",
        "\n",
        "    if not all_errors:\n",
        "        print(\"‚úÖ ALL OPERATIONS VERIFIED SUCCESSFULLY\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  VERIFICATION COMPLETED WITH DISCREPANCIES\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# ========== FINAL WORKFLOW SUMMARY ==========\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"WORKFLOW COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Summary:\")\n",
        "print(f\"  - ASSESS files processed: {len(assess_matched)} updated\")\n",
        "if USE_SYNAPSE_STAGING:\n",
        "    print(f\"  - ASSESS new files: {len(assess_new_only)} moved\")\n",
        "print(f\"  - PREVENT files processed: {len(prevent_matched)} updated\")\n",
        "if USE_SYNAPSE_STAGING:\n",
        "    print(f\"  - PREVENT new files: {len(prevent_new_only)} moved\")\n",
        "print(f\"  - Version: {VERSION_LABEL}\")\n",
        "print(f\"  - Workflow mode: {'Synapse-based' if USE_SYNAPSE_STAGING else 'Local files'}\")\n",
        "print(f\"  - DRY_RUN: {DRY_RUN}\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "amp-als",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
